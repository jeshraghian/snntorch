{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e3d2cb6c6594c8fb1ac5ae9e4ac6252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41fe1c9e71064cd4ab609cc6fd3c9d7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a270f878e5640799a5c605567fc30db",
              "IPY_MODEL_4b510ce801d646f790bbb0b6524600c0"
            ]
          }
        },
        "41fe1c9e71064cd4ab609cc6fd3c9d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a270f878e5640799a5c605567fc30db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbfdd722375c48009e846fd7cbceba06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b7cdc114ca84669951c47b654e8c20c"
          }
        },
        "4b510ce801d646f790bbb0b6524600c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ea3503374c04bcab23d49d579142dc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1466216.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c1a7ec286e14c61a4915bdf8077041a"
          }
        },
        "fbfdd722375c48009e846fd7cbceba06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b7cdc114ca84669951c47b654e8c20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ea3503374c04bcab23d49d579142dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c1a7ec286e14c61a4915bdf8077041a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5d97f8e9e7946aa9309d62b8b5867f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8b648fbad3e41a1a130dd1199cb352e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa88899f870d4df1aeecbd4fb26f3db2",
              "IPY_MODEL_01e4a747c46c4f0ba23a3a378e10d052"
            ]
          }
        },
        "d8b648fbad3e41a1a130dd1199cb352e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa88899f870d4df1aeecbd4fb26f3db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_984d355bab9a4ef6b6e095ae13594c26",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_569d85264a1347d6826e359537399808"
          }
        },
        "01e4a747c46c4f0ba23a3a378e10d052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0d0724c2c79425087578c227bf71af9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b24df9f6a8794288be7e72e5a6000954"
          }
        },
        "984d355bab9a4ef6b6e095ae13594c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "569d85264a1347d6826e359537399808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0d0724c2c79425087578c227bf71af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b24df9f6a8794288be7e72e5a6000954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ce279872832405f94241fb6d658fcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a71736cb3e0d4b4b84f89d30d7f734c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9db26894a931435691b535e0ed6f0733",
              "IPY_MODEL_109c08cf0bfa4eed9298b520e2cd7906"
            ]
          }
        },
        "a71736cb3e0d4b4b84f89d30d7f734c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9db26894a931435691b535e0ed6f0733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d98f6ea580e74b2ea4de410ff8f0e40a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fedd965838774a5e976c72c936e7a47b"
          }
        },
        "109c08cf0bfa4eed9298b520e2cd7906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf7e596553be4683ba661bec4f238f68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:07&lt;00:00, 235860.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3136bfeaf4c24ac7bc236050bdd62308"
          }
        },
        "d98f6ea580e74b2ea4de410ff8f0e40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fedd965838774a5e976c72c936e7a47b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf7e596553be4683ba661bec4f238f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3136bfeaf4c24ac7bc236050bdd62308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16576360fc6a4e82840e7974a1d8e0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d58891d14b84e7c9716a12850824d58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41c3b72a47bc4d48a89b992aef355160",
              "IPY_MODEL_4054032e518e4be592a7c8c2c41fcef4"
            ]
          }
        },
        "1d58891d14b84e7c9716a12850824d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41c3b72a47bc4d48a89b992aef355160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52457d5c56f84e2885ad7f0850daded6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dec5a801c3b64815abf7fb5ab4aaf93b"
          }
        },
        "4054032e518e4be592a7c8c2c41fcef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_caa455f6c5004552835cd86df5312701",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:06&lt;00:00, 1302.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23eead4552e84f3aa1d5bead98c2ca25"
          }
        },
        "52457d5c56f84e2885ad7f0850daded6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dec5a801c3b64815abf7fb5ab4aaf93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "caa455f6c5004552835cd86df5312701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23eead4552e84f3aa1d5bead98c2ca25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/binary_weights/examples/binary_snn_no_conflict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOyd0FJMbWki"
      },
      "source": [
        "# **SNN with binary weights**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "S733HbldaB40"
      },
      "source": [
        "# Gradient-based Learning in Convolutional Spiking Neural Networks\n",
        "In this tutorial, we'll use a convolutional neural network (CNN) to classify the MNIST dataset.\n",
        "We will use the backpropagation through time (BPTT) algorithm to do so. This tutorial is largely the same as tutorial 2, just with a different network architecture to show how to integrate convolutions with snnTorch.\n",
        "\n",
        "If running in Google Colab:\n",
        "* Ensure you are connected to GPU by checking Runtime > Change runtime type > Hardware accelerator: GPU\n",
        "* Next, install the Test PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YgGUk8EJaB41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6dd45d-fd51-4345-e17b-905de475101d"
      },
      "source": [
        "# Install the test PyPi Distribution of snntorch\n",
        "\n",
        "# !pip uninstall snntorch\n",
        "!pip install -i https://test.pypi.org/simple/ snntorch\n",
        "# !pip install git+https://github.com/jeshraghian/snntorch.git@binary_weights#egg=snntorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Collecting snntorch\n",
            "  Downloading https://test-files.pythonhosted.org/packages/4e/71/23d35f42916ae8ec8a1a3bd3dc98804a09587ca9b6971e0ebaa80a6c5234/snntorch-0.0.9-py3-none-any.whl\n",
            "Installing collected packages: snntorch\n",
            "Successfully installed snntorch-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_UAKn7UoaB41"
      },
      "source": [
        "## 1. Setting up the Static MNIST Dataset\n",
        "### 1.1. Import packages and setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JGneJnSiaB42"
      },
      "source": [
        "import snntorch as snn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PWL3FQSSaB42"
      },
      "source": [
        "### 1.2 Define network and SNN parameters\n",
        "We will use a 2conv-2MaxPool-FCN architecture for a sequence of 25 time steps.\n",
        "\n",
        "* `alpha` is the decay rate of the synaptic current of a neuron\n",
        "* `beta` is the decay rate of the membrane potential of a neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kvzf29tIaB42"
      },
      "source": [
        "# Network Architecture\n",
        "num_inputs = 28*28\n",
        "num_outputs = 10\n",
        "num_hidden = 1000\n",
        "# Training Parameters\n",
        "batch_size=128\n",
        "data_path='/data/mnist'\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 32\n",
        "time_step = 1e-3\n",
        "# tau_mem = 6.5e-4\n",
        "# tau_syn = 5.5e-4\n",
        "# alpha = float(np.exp(-time_step/tau_syn))\n",
        "# beta = float(np.exp(-time_step/tau_mem))\n",
        "alpha = 0.3\n",
        "beta = 0.3\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4_5wuLk0aB43"
      },
      "source": [
        "### 1.3 Download MNIST Dataset\n",
        "To see how to construct a validation set, refer to Tutorial 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WJO7iy-7aB43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "5e3d2cb6c6594c8fb1ac5ae9e4ac6252",
            "41fe1c9e71064cd4ab609cc6fd3c9d7b",
            "5a270f878e5640799a5c605567fc30db",
            "4b510ce801d646f790bbb0b6524600c0",
            "fbfdd722375c48009e846fd7cbceba06",
            "5b7cdc114ca84669951c47b654e8c20c",
            "3ea3503374c04bcab23d49d579142dc2",
            "7c1a7ec286e14c61a4915bdf8077041a",
            "f5d97f8e9e7946aa9309d62b8b5867f8",
            "d8b648fbad3e41a1a130dd1199cb352e",
            "fa88899f870d4df1aeecbd4fb26f3db2",
            "01e4a747c46c4f0ba23a3a378e10d052",
            "984d355bab9a4ef6b6e095ae13594c26",
            "569d85264a1347d6826e359537399808",
            "f0d0724c2c79425087578c227bf71af9",
            "b24df9f6a8794288be7e72e5a6000954",
            "8ce279872832405f94241fb6d658fcae",
            "a71736cb3e0d4b4b84f89d30d7f734c7",
            "9db26894a931435691b535e0ed6f0733",
            "109c08cf0bfa4eed9298b520e2cd7906",
            "d98f6ea580e74b2ea4de410ff8f0e40a",
            "fedd965838774a5e976c72c936e7a47b",
            "bf7e596553be4683ba661bec4f238f68",
            "3136bfeaf4c24ac7bc236050bdd62308",
            "16576360fc6a4e82840e7974a1d8e0d4",
            "1d58891d14b84e7c9716a12850824d58",
            "41c3b72a47bc4d48a89b992aef355160",
            "4054032e518e4be592a7c8c2c41fcef4",
            "52457d5c56f84e2885ad7f0850daded6",
            "dec5a801c3b64815abf7fb5ab4aaf93b",
            "caa455f6c5004552835cd86df5312701",
            "23eead4552e84f3aa1d5bead98c2ca25"
          ]
        },
        "outputId": "81bfc97d-0033-4e91-a3a4-7a94074ffcc7"
      },
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e3d2cb6c6594c8fb1ac5ae9e4ac6252",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5d97f8e9e7946aa9309d62b8b5867f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ce279872832405f94241fb6d658fcae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16576360fc6a4e82840e7974a1d8e0d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6_guKA__aB44"
      },
      "source": [
        "### 1.4 Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cQzrUSKRaB44"
      },
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "jHBwr32UaB44"
      },
      "source": [
        "## 2. Define Network\n",
        "To define our network, we will import two functions from the `snntorch.neuron` module, which contains a series of neuron models and related functions.\n",
        "snnTorch treats neurons as activations with recurrent connections, so that it integrates smoothly with PyTorch's pre-existing layer functions.\n",
        "* `snntorch.neuron.LIF` is a simple Leaky Integrate and Fire (LIF) neuron. Specifically, it uses Stein's model which assumes instantaneous rise times for synaptic current and membrane potential.\n",
        "* `snntorch.neuron.FastSigmoidSurrogate` defines separate forward and backward functions. The forward function is a Heaviside step function for spike generation. The backward function is the derivative of a fast sigmoid function, to ensure continuous differentiability.\n",
        "FSS is mostly derived from:\n",
        "\n",
        ">Neftci, E. O., Mostafa, H., and Zenke, F. (2019) Surrogate Gradient Learning in Spiking Neural Networks. https://arxiv.org/abs/1901/09948\n",
        "\n",
        "`snn.neuron.slope` is a variable that defines the slope of the backward surrogate.\n",
        "TO-DO: Include visualisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2JKR_90daB45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "82ef2e1c-5ed2-4a4e-d0b2-7eb6c688469a"
      },
      "source": [
        "spike_grad = snn.FastSigmoidSurrogate.apply\n",
        "snn.slope = 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1502cfba5f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspike_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastSigmoidSurrogate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'snntorch' has no attribute 'FastSigmoidSurrogate'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "LaXzsI6baB45"
      },
      "source": [
        "Now we can define our SNN. Defining an instance of `LIF` requires three arguments: 1) the surrogate spiking function, 2) $I_{syn}$ decay rate, $\\alpha$, and 3) $V_{mem}$ decay rate, $\\beta$.\n",
        "\n",
        "The LIF neuron is simply treated as a recurrent activation. It requires initialization of the post-synaptic spikes `spk1` and `spk2`, the synaptic current `syn1` and `syn2`, and the membrane potential `mem1` and `mem2`.\n",
        "\n",
        "We will use the final layer spikes and membrane for determining loss and accuracy, so we will record and return their histories in `spk3_rec` and `mem3_rec`.\n",
        "\n",
        "Keep in mind, the dataset we are using is just static MNIST. I.e., it is *not* time-varying.\n",
        "Therefore, we pass the same MNIST sample to the input at each time step.\n",
        "This is handled in the line `cur1 = F.max_pool2d(self.conv1(x), 2)`, where `x` is the same input over the whole for-loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zAnnWfGyfhkf"
      },
      "source": [
        "### Binarized Layer Modules\n",
        "``Binarize`` converts weights to {-1, 1}.\n",
        "Remove `.mul_(2).add_(1)` for {0, 1}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "blVwJakcaB46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30e2a27-de3c-4bc9-e355-7c9f105f8619"
      },
      "source": [
        "import pdb\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Binarize(tensor,quant_mode='det'):\n",
        "    if quant_mode=='det':\n",
        "        return tensor.sign()\n",
        "        # tmp = tensor.clone()\n",
        "        # tmp[tensor>0] = 1\n",
        "        # tmp[tensor==0] = 0\n",
        "        # tmp[tensor<0] = -1\n",
        "        # return tmp\n",
        "    else:\n",
        "        return tensor.add_(1).div_(2).add_(torch.rand(tensor.size()).add(-0.5)).clamp_(0,1).round().mul_(2).add_(-1)\n",
        "\n",
        "\n",
        "class HingeLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HingeLoss,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def hinge_loss(self,input,target):\n",
        "            #import pdb; pdb.set_trace()\n",
        "            output=self.margin-input.mul(target)\n",
        "            output[output.le(0)]=0\n",
        "            return output.mean()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return self.hinge_loss(input,target)\n",
        "\n",
        "class SqrtHingeLossFunction(Function):\n",
        "    def __init__(self):\n",
        "        super(SqrtHingeLossFunction,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        output=self.margin-input.mul(target)\n",
        "        output[output.le(0)]=0\n",
        "        self.save_for_backward(input, target)\n",
        "        loss=output.mul(output).sum(0).sum(1).div(target.numel())\n",
        "        return loss\n",
        "\n",
        "    def backward(self,grad_output):\n",
        "       input, target = self.saved_tensors\n",
        "       output=self.margin-input.mul(target)\n",
        "       output[output.le(0)]=0\n",
        "       import pdb; pdb.set_trace()\n",
        "       grad_output.resize_as_(input).copy_(target).mul_(-2).mul_(output)\n",
        "       grad_output.mul_(output.ne(0).float())\n",
        "       grad_output.div_(input.numel())\n",
        "       return grad_output,grad_output\n",
        "\n",
        "def Quantize(tensor,quant_mode='det',  params=None, numBits=8):\n",
        "    tensor.clamp_(-2**(numBits-1),2**(numBits-1))\n",
        "    if quant_mode=='det':\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().div(2**(numBits-1))\n",
        "    else:\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().add(torch.rand(tensor.size()).add(-0.5)).div(2**(numBits-1))\n",
        "        quant_fixed(tensor, params)\n",
        "    return tensor\n",
        "\n",
        "# import torch.nn._functions as tnnf\n",
        "\n",
        "\n",
        "class BinarizeLinear(nn.Linear):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if input.size(1) != 784:\n",
        "            input.data=Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "        out = nn.functional.linear(input, self.weight)\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1).expand_as(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BinarizeConv2d(nn.Conv2d):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeConv2d, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.size(1) != 3:\n",
        "            input.data = Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "\n",
        "        out = nn.functional.conv2d(input, self.weight, None, self.stride,\n",
        "                                   self.padding, self.dilation, self.groups)\n",
        "\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1, 1, 1).expand_as(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuKfWeZrh50P"
      },
      "source": [
        "class LIF(nn.Module):\n",
        "    \"\"\"Parent class for leaky integrate and fire neuron models.\"\"\"\n",
        "    instances = []\n",
        "    def __init__(self, alpha, beta, threshold=1.0, spike_grad=None):\n",
        "        super(LIF, self).__init__()\n",
        "        LIF.instances.append(self)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.threshold = threshold\n",
        "\n",
        "        if spike_grad is None:\n",
        "            self.spike_grad = self.Heaviside.apply\n",
        "        else:\n",
        "            self.spike_grad = spike_grad\n",
        "\n",
        "    def fire(self, mem):\n",
        "        \"\"\"Generates spike if mem > threshold.\n",
        "        Returns spk and reset.\"\"\"\n",
        "        mem_shift = mem - self.threshold\n",
        "        spk = self.spike_grad(mem_shift).to(device)\n",
        "        reset = torch.zeros_like(mem)\n",
        "        spk_idx = (mem_shift > 0)\n",
        "        reset[spk_idx] = torch.ones_like(mem)[spk_idx]\n",
        "        return spk, reset\n",
        "\n",
        "    def fire_single(self, mem):\n",
        "        \"\"\"Generates spike if mem > threshold.\n",
        "        Returns spk and reset.\"\"\"\n",
        "        mem_shift = mem - self.threshold\n",
        "        \n",
        "        index = torch.argmax(mem_shift, dim=-1)\n",
        "        \n",
        "        spk_tmp = self.spike_grad(mem_shift)\n",
        "\n",
        "        mask_spk1 = torch.zeros_like(spk_tmp)\n",
        "        # print(mem.size())\n",
        "        # print(index.size())\n",
        "        mask_spk1[torch.arange(mem_shift.size()[0]), index] = 1\n",
        "        spk = (spk_tmp * mask_spk1).to(device)\n",
        "        # print(spk[0])\n",
        "        reset = torch.zeros_like(mem)\n",
        "        spk_idx = (mem_shift > 0)\n",
        "        reset[spk_idx] = torch.ones_like(mem)[spk_idx]\n",
        "        return spk, reset\n",
        "\n",
        "    @classmethod\n",
        "    def clear_instances(cls):\n",
        "      cls.instances = []\n",
        "\n",
        "    @staticmethod\n",
        "    def init_stein(batch_size, *args):\n",
        "        \"\"\"Used to initialize syn, mem and spk.\n",
        "        *args are the input feature dimensions.\n",
        "        E.g., batch_size=128 and input feature of size=1x28x28 would require init_hidden(128, 1, 28, 28).\"\"\"\n",
        "        syn = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        mem = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        spk = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "\n",
        "        return spk, syn, mem\n",
        "\n",
        "    @staticmethod\n",
        "    def init_srm0(batch_size, *args):\n",
        "        \"\"\"Used to initialize syn_pre, syn_post, mem and spk.\n",
        "        *args are the input feature dimensions.\n",
        "        E.g., batch_size=128 and input feature of size=1x28x28 would require init_hidden(128, 1, 28, 28).\"\"\"\n",
        "        syn_pre = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        syn_post = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        mem = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        spk = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "\n",
        "        return spk, syn_pre, syn_post, mem\n",
        "\n",
        "    @staticmethod\n",
        "    def detach(*args):\n",
        "        \"\"\"Used to detach input arguments from the current graph.\n",
        "        Intended for use in truncated backpropagation through time where hidden state variables are global variables.\"\"\"\n",
        "        for state in args:\n",
        "            state.detach_()\n",
        "\n",
        "    @staticmethod\n",
        "    def zeros(*args):\n",
        "        \"\"\"Used to clear hidden state variables to zero.\n",
        "            Intended for use where hidden state variables are global variables.\"\"\"\n",
        "        for state in args:\n",
        "            state = torch.zeros_like(state)\n",
        "\n",
        "    @staticmethod\n",
        "    class Heaviside(torch.autograd.Function):\n",
        "        \"\"\"Default and non-approximate spiking function for neuron.\n",
        "        Forward pass: Heaviside step function.\n",
        "        Backward pass: Dirac Delta clipped to 1 at x>0 instead of inf at x=1.\n",
        "        This assumption holds true on the basis that a spike occurs as long as x>0 and the following time step incurs a reset.\"\"\"\n",
        "\n",
        "        @staticmethod\n",
        "        def forward(ctx, input_):\n",
        "            ctx.save_for_backward(input_)\n",
        "            out = torch.zeros_like(input_)\n",
        "            out[input_ > 0] = 1.0\n",
        "            return out\n",
        "\n",
        "        @staticmethod\n",
        "        def backward(ctx, grad_output):\n",
        "            input_, = ctx.saved_tensors\n",
        "            grad_input = grad_output.clone()\n",
        "            grad_input[input_ < 0] = 0.0\n",
        "            grad = grad_input\n",
        "            return grad\n",
        "\n",
        "class Stein_single(LIF):\n",
        "    \"\"\"\n",
        "    Stein's model of the leaky integrate and fire neuron.\n",
        "    The synaptic current jumps upon spike arrival, which causes a jump in membrane potential.\n",
        "    Synaptic current and membrane potential decay exponentially with rates of alpha and beta, respectively.\n",
        "    For mem[T] > threshold, spk[T+1] = 0 to account for axonal delay.\n",
        "\n",
        "    For further reading, see:\n",
        "    R. B. Stein (1965) A theoretical analysis of neuron variability. Biophys. J. 5, pp. 173-194.\n",
        "    R. B. Stein (1967) Some models of neuronal variability. Biophys. J. 7. pp. 37-68.\"\"\"\n",
        "\n",
        "    def __init__(self, alpha, beta, threshold=1.0, num_inputs=False, spike_grad=None, batch_size=False, hidden_init=False):\n",
        "        super(Stein_single, self).__init__(alpha, beta, threshold, spike_grad)\n",
        "\n",
        "        self.num_inputs = num_inputs\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_init = hidden_init\n",
        "\n",
        "        if self.hidden_init:\n",
        "            if not self.num_inputs:\n",
        "                raise ValueError(\"num_inputs must be specified to initialize hidden states as instance variables.\")\n",
        "            elif not self.batch_size:\n",
        "                raise ValueError(\"batch_size must be specified to initialize hidden states as instance variables.\")\n",
        "            elif hasattr(self.num_inputs, '__iter__'):\n",
        "                self.spk, self.syn, self.mem = self.init_stein(self.batch_size, *(self.num_inputs)) # need to automatically call batch_size\n",
        "            else:\n",
        "                self.spk, self.syn, self.mem = self.init_stein(self.batch_size, self.num_inputs)\n",
        "\n",
        "    def forward(self, input_, syn, mem):\n",
        "        if not self.hidden_init:\n",
        "            spk, reset = self.fire(mem)\n",
        "            input_[input_>1] = 1\n",
        "            input_[input_<-1] = -1\n",
        "            syn = self.alpha * syn + input_\n",
        "            mem = self.beta * mem + syn - reset\n",
        "\n",
        "            return spk, syn, mem\n",
        "\n",
        "        # intended for truncated-BPTT where instance variables are hidden states\n",
        "        if self.hidden_init:\n",
        "            self.spk, self.reset = self.fire(self.mem)\n",
        "            self.syn = self.alpha * self.syn + input_\n",
        "            self.mem = self.beta * self.mem + self.syn - self.reset\n",
        "\n",
        "            return self.spk, self.syn, self.mem\n",
        "\n",
        "    @classmethod\n",
        "    def detach_hidden(cls):\n",
        "        \"\"\"Used to detach hidden states from the current graph.\n",
        "        Intended for use in truncated backpropagation through time where hidden state variables are instance variables.\"\"\"\n",
        "\n",
        "        for layer in range(len(cls.instances)):\n",
        "            cls.instances[layer].spk.detach_()\n",
        "            cls.instances[layer].syn.detach_()\n",
        "            cls.instances[layer].mem.detach_()\n",
        "\n",
        "    @classmethod\n",
        "    def zeros_hidden(cls):\n",
        "        \"\"\"Used to clear hidden state variables to zero.\n",
        "        Intended for use where hidden state variables are instance variables.\"\"\"\n",
        "\n",
        "        for layer in range(len(cls.instances)):\n",
        "            cls.instances[layer].spk = torch.zeros_like(cls.instances[layer].spk)\n",
        "            cls.instances[layer].syn = torch.zeros_like(cls.instances[layer].syn)\n",
        "            cls.instances[layer].mem = torch.zeros_like(cls.instances[layer].mem)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZNySTB6wfhkk"
      },
      "source": [
        "Network: Low precision forward pass, high precision backprop (Additional Mod in Optimization method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZAxmcjuefhkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df99acf-d5ca-4bb5-a243-af05b973f714"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        # self.bn0 = nn.BatchNorm1d(784)\n",
        "        self.fc1 = BinarizeLinear(784, num_hidden)\n",
        "        self.lif1 = Stein_single(alpha=alpha, beta=beta)\n",
        "\n",
        "        self.fc2 = BinarizeLinear(num_hidden, num_outputs)\n",
        "        self.lif2 = Stein_single(alpha=alpha, beta=beta)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "        self.idx1 = torch.arange(batch_size)\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "            # index = torch.argmax(spk1_tmp, dim=1)\n",
        "            # mask_spk1 = torch.zeros_like(spk1_tmp)\n",
        "            # mask_spk1[self.idx1, index] = 1\n",
        "            # spk1 = spk1_tmp * mask_spk1\n",
        "            # spk1[:, index] = 1;\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)\n",
        "print(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FOJTim88fhkn"
      },
      "source": [
        "Old network (if using above net, don't run the following code block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1CFB6LAJaB47"
      },
      "source": [
        "## 3. Training\n",
        "Time for training! Let's first define a couple of functions to print out test/train accuracy for each minibatch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7V0_NGKSaB48"
      },
      "source": [
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    output, _ = net(data.view(batch_size, -1))\n",
        "    # output, _ = net(data.view(batch_size, 1, 28, 28))\n",
        "    _, am = output.sum(dim=0).max(1)\n",
        "    acc = np.mean((targets == am). detach().cpu().numpy())\n",
        "\n",
        "    if train is True:\n",
        "        print(f\"Train Set Accuracy: {acc}\")\n",
        "    else:\n",
        "        print(f\"Test Set Accuracy: {acc}\")\n",
        "\n",
        "def train_printer():\n",
        "    print(f\"Epoch {epoch}, Minibatch {minibatch_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]}\")\n",
        "    print_batch_accuracy(data_it, targets_it, train=True)\n",
        "    print_batch_accuracy(testdata_it, testtargets_it, train=False)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9uVWFKdXaB48"
      },
      "source": [
        "### 3.1 Optimizer & Loss\n",
        "We'll apply the softmax function to the membrane potentials of the output layer in calculating a negative log-likelihood loss.\n",
        "The Adam optimizer is used for weight updates.\n",
        "\n",
        "Accuracy is measured by counting the spikes of the output neurons. The neuron that fires the most frequently will be our predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I4BNFQkBaB48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b2fff6-35fb-48b7-9baf-68e00699f595"
      },
      "source": [
        "lr = 2e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
        "loss_fn = nn.NLLLoss()\n",
        "print(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0enleDrOaB49"
      },
      "source": [
        "### 3.2 Training Loop\n",
        "Now just sit back, relax, and wait for convergence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgPDDt5Xs8U-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327fb938-6ffa-4a1d-8a12-ed973cb57c4b"
      },
      "source": [
        "# tmp = torch.tensor([[1, 0,0,1], [0,1, 1, 0]])\r\n",
        "# print(tmp)\r\n",
        "# tmp_index = torch.argmax(tmp, dim=1)\r\n",
        "# len = torch.arange(2)\r\n",
        "# print(len)\r\n",
        "# print(tmp_index)\r\n",
        "# mask = torch.zeros_like(tmp)\r\n",
        "# mask[len, tmp_index] = 1\r\n",
        "# print(tmp * mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 0, 0, 1],\n",
            "        [0, 1, 1, 0]])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "tensor([[1, 0, 0, 0],\n",
            "        [0, 1, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JpdYo0G6fhkp"
      },
      "source": [
        "High precision BPTT training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P225z9fafhkq",
        "outputId": "4b4da79b-ffee-4f29-bf98-0f859e24f6df"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    new_lr = lr * (0.85 ** epoch)\n",
        "    # lr = lr\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_lr\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(6):\n",
        "    print(batch_size)\n",
        "    minibatch_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in train_batch:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        output, mem_rec = net(data_it.view(batch_size, -1))\n",
        "        # output, mem_rec = net(data_it.view(batch_size, 1, 28, 28)) # [28x28] or [1x28x28]?\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "\n",
        "        # adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # BNN OPTimization\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.data.copy_(p.org)\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.org.copy_(p.data.clamp_(-1,1))\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(testdata_it.view(batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(testdata_it.view(batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "          train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "    # print(batch_size)\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # print(images.size())\n",
        "\n",
        "        # If current batch matches batch_size, just do the usual thing\n",
        "        if images.size()[0] == batch_size:\n",
        "          outputs, _ = net(images.view(batch_size, -1))\n",
        "          # outputs, _ = net(images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "        # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "        # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "        else:\n",
        "          temp_bs = batch_size\n",
        "          batch_size = images.size()[0]\n",
        "          outputs, _ = net(images.view(images.size()[0], -1))\n",
        "          # outputs, _ = net(images.view(images.size()[0], 1, 28, 28))\n",
        "          batch_size = temp_bs\n",
        "\n",
        "        _, predicted = outputs.sum(dim=0).max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "    print(f\"Test Set Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "Epoch 0, Minibatch 0\n",
            "Train Set Loss: 92.80427551269531\n",
            "Test Set Loss: 93.1279525756836\n",
            "Train Set Accuracy: 0.078125\n",
            "Test Set Accuracy: 0.0625\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 50\n",
            "Train Set Loss: 72.2509994506836\n",
            "Test Set Loss: 72.39795684814453\n",
            "Train Set Accuracy: 0.34375\n",
            "Test Set Accuracy: 0.2890625\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 100\n",
            "Train Set Loss: 57.10384750366211\n",
            "Test Set Loss: 52.557437896728516\n",
            "Train Set Accuracy: 0.5703125\n",
            "Test Set Accuracy: 0.6171875\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 150\n",
            "Train Set Loss: 52.889259338378906\n",
            "Test Set Loss: 49.155208587646484\n",
            "Train Set Accuracy: 0.65625\n",
            "Test Set Accuracy: 0.7109375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 200\n",
            "Train Set Loss: 53.81201171875\n",
            "Test Set Loss: 47.201961517333984\n",
            "Train Set Accuracy: 0.6328125\n",
            "Test Set Accuracy: 0.7265625\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 250\n",
            "Train Set Loss: 47.81491470336914\n",
            "Test Set Loss: 47.04018783569336\n",
            "Train Set Accuracy: 0.7421875\n",
            "Test Set Accuracy: 0.7578125\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 300\n",
            "Train Set Loss: 49.837501525878906\n",
            "Test Set Loss: 46.21890640258789\n",
            "Train Set Accuracy: 0.71875\n",
            "Test Set Accuracy: 0.78125\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 350\n",
            "Train Set Loss: 45.386356353759766\n",
            "Test Set Loss: 48.83235549926758\n",
            "Train Set Accuracy: 0.8359375\n",
            "Test Set Accuracy: 0.7109375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 400\n",
            "Train Set Loss: 45.8553466796875\n",
            "Test Set Loss: 47.34769821166992\n",
            "Train Set Accuracy: 0.7578125\n",
            "Test Set Accuracy: 0.7421875\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 450\n",
            "Train Set Loss: 44.06976318359375\n",
            "Test Set Loss: 45.036949157714844\n",
            "Train Set Accuracy: 0.8203125\n",
            "Test Set Accuracy: 0.7421875\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 7966/10000\n",
            "Test Set Accuracy: 79.66%\n",
            "128\n",
            "Epoch 1, Minibatch 32\n",
            "Train Set Loss: 45.654388427734375\n",
            "Test Set Loss: 46.795623779296875\n",
            "Train Set Accuracy: 0.8046875\n",
            "Test Set Accuracy: 0.734375\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 82\n",
            "Train Set Loss: 44.91303634643555\n",
            "Test Set Loss: 44.6005973815918\n",
            "Train Set Accuracy: 0.8359375\n",
            "Test Set Accuracy: 0.8359375\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 132\n",
            "Train Set Loss: 44.52462387084961\n",
            "Test Set Loss: 44.16183090209961\n",
            "Train Set Accuracy: 0.8671875\n",
            "Test Set Accuracy: 0.7734375\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 182\n",
            "Train Set Loss: 44.32490921020508\n",
            "Test Set Loss: 43.292236328125\n",
            "Train Set Accuracy: 0.8203125\n",
            "Test Set Accuracy: 0.8203125\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 232\n",
            "Train Set Loss: 40.48457717895508\n",
            "Test Set Loss: 44.49838638305664\n",
            "Train Set Accuracy: 0.859375\n",
            "Test Set Accuracy: 0.7890625\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 282\n",
            "Train Set Loss: 45.122474670410156\n",
            "Test Set Loss: 43.55217742919922\n",
            "Train Set Accuracy: 0.765625\n",
            "Test Set Accuracy: 0.78125\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 332\n",
            "Train Set Loss: 43.63691711425781\n",
            "Test Set Loss: 41.98851776123047\n",
            "Train Set Accuracy: 0.84375\n",
            "Test Set Accuracy: 0.84375\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 382\n",
            "Train Set Loss: 43.40782165527344\n",
            "Test Set Loss: 41.84636306762695\n",
            "Train Set Accuracy: 0.8515625\n",
            "Test Set Accuracy: 0.8203125\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 432\n",
            "Train Set Loss: 42.16743087768555\n",
            "Test Set Loss: 42.26407241821289\n",
            "Train Set Accuracy: 0.8203125\n",
            "Test Set Accuracy: 0.859375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 8520/10000\n",
            "Test Set Accuracy: 85.2%\n",
            "128\n",
            "Epoch 2, Minibatch 14\n",
            "Train Set Loss: 43.58816146850586\n",
            "Test Set Loss: 42.80744552612305\n",
            "Train Set Accuracy: 0.8125\n",
            "Test Set Accuracy: 0.859375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 64\n",
            "Train Set Loss: 43.64288330078125\n",
            "Test Set Loss: 41.297447204589844\n",
            "Train Set Accuracy: 0.8359375\n",
            "Test Set Accuracy: 0.8828125\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 114\n",
            "Train Set Loss: 43.02156066894531\n",
            "Test Set Loss: 40.6720085144043\n",
            "Train Set Accuracy: 0.84375\n",
            "Test Set Accuracy: 0.8359375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 164\n",
            "Train Set Loss: 44.469085693359375\n",
            "Test Set Loss: 42.473785400390625\n",
            "Train Set Accuracy: 0.7734375\n",
            "Test Set Accuracy: 0.8359375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 214\n",
            "Train Set Loss: 40.893253326416016\n",
            "Test Set Loss: 44.627098083496094\n",
            "Train Set Accuracy: 0.890625\n",
            "Test Set Accuracy: 0.7890625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 264\n",
            "Train Set Loss: 41.724388122558594\n",
            "Test Set Loss: 39.7031135559082\n",
            "Train Set Accuracy: 0.8671875\n",
            "Test Set Accuracy: 0.9140625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 314\n",
            "Train Set Loss: 42.83528137207031\n",
            "Test Set Loss: 40.48007583618164\n",
            "Train Set Accuracy: 0.8046875\n",
            "Test Set Accuracy: 0.890625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 364\n",
            "Train Set Loss: 42.281494140625\n",
            "Test Set Loss: 41.32661819458008\n",
            "Train Set Accuracy: 0.859375\n",
            "Test Set Accuracy: 0.8671875\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 414\n",
            "Train Set Loss: 42.20060729980469\n",
            "Test Set Loss: 43.23695373535156\n",
            "Train Set Accuracy: 0.859375\n",
            "Test Set Accuracy: 0.8203125\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 464\n",
            "Train Set Loss: 40.966678619384766\n",
            "Test Set Loss: 42.03770065307617\n",
            "Train Set Accuracy: 0.9140625\n",
            "Test Set Accuracy: 0.84375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 8708/10000\n",
            "Test Set Accuracy: 87.08%\n",
            "128\n",
            "Epoch 3, Minibatch 46\n",
            "Train Set Loss: 41.376548767089844\n",
            "Test Set Loss: 43.65398025512695\n",
            "Train Set Accuracy: 0.8671875\n",
            "Test Set Accuracy: 0.84375\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 96\n",
            "Train Set Loss: 40.95401382446289\n",
            "Test Set Loss: 41.7711067199707\n",
            "Train Set Accuracy: 0.8984375\n",
            "Test Set Accuracy: 0.8671875\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 146\n",
            "Train Set Loss: 41.628456115722656\n",
            "Test Set Loss: 42.38728713989258\n",
            "Train Set Accuracy: 0.8828125\n",
            "Test Set Accuracy: 0.890625\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 196\n",
            "Train Set Loss: 43.64141082763672\n",
            "Test Set Loss: 42.43144607543945\n",
            "Train Set Accuracy: 0.8515625\n",
            "Test Set Accuracy: 0.8125\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 246\n",
            "Train Set Loss: 43.28754806518555\n",
            "Test Set Loss: 44.503990173339844\n",
            "Train Set Accuracy: 0.859375\n",
            "Test Set Accuracy: 0.8203125\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 296\n",
            "Train Set Loss: 41.727664947509766\n",
            "Test Set Loss: 41.554931640625\n",
            "Train Set Accuracy: 0.9140625\n",
            "Test Set Accuracy: 0.859375\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 346\n",
            "Train Set Loss: 42.252838134765625\n",
            "Test Set Loss: 43.8138542175293\n",
            "Train Set Accuracy: 0.890625\n",
            "Test Set Accuracy: 0.8125\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 396\n",
            "Train Set Loss: 42.85002517700195\n",
            "Test Set Loss: 42.75204086303711\n",
            "Train Set Accuracy: 0.84375\n",
            "Test Set Accuracy: 0.8515625\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 446\n",
            "Train Set Loss: 42.107627868652344\n",
            "Test Set Loss: 41.515106201171875\n",
            "Train Set Accuracy: 0.8828125\n",
            "Test Set Accuracy: 0.8984375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 8634/10000\n",
            "Test Set Accuracy: 86.34%\n",
            "128\n",
            "Epoch 4, Minibatch 28\n",
            "Train Set Loss: 44.652889251708984\n",
            "Test Set Loss: 41.73366928100586\n",
            "Train Set Accuracy: 0.8515625\n",
            "Test Set Accuracy: 0.875\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 78\n",
            "Train Set Loss: 41.77414321899414\n",
            "Test Set Loss: 41.31425476074219\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.875\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 128\n",
            "Train Set Loss: 40.97462844848633\n",
            "Test Set Loss: 41.3787841796875\n",
            "Train Set Accuracy: 0.890625\n",
            "Test Set Accuracy: 0.828125\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 178\n",
            "Train Set Loss: 43.20564651489258\n",
            "Test Set Loss: 41.6748046875\n",
            "Train Set Accuracy: 0.796875\n",
            "Test Set Accuracy: 0.890625\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 228\n",
            "Train Set Loss: 42.618587493896484\n",
            "Test Set Loss: 40.27058029174805\n",
            "Train Set Accuracy: 0.8671875\n",
            "Test Set Accuracy: 0.8984375\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 278\n",
            "Train Set Loss: 39.406036376953125\n",
            "Test Set Loss: 42.60047149658203\n",
            "Train Set Accuracy: 0.9140625\n",
            "Test Set Accuracy: 0.8515625\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 328\n",
            "Train Set Loss: 42.31239700317383\n",
            "Test Set Loss: 42.19221115112305\n",
            "Train Set Accuracy: 0.8984375\n",
            "Test Set Accuracy: 0.890625\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 378\n",
            "Train Set Loss: 41.391990661621094\n",
            "Test Set Loss: 42.4847297668457\n",
            "Train Set Accuracy: 0.8671875\n",
            "Test Set Accuracy: 0.8125\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 428\n",
            "Train Set Loss: 41.478233337402344\n",
            "Test Set Loss: 39.857154846191406\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.8984375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 8761/10000\n",
            "Test Set Accuracy: 87.61%\n",
            "128\n",
            "Epoch 5, Minibatch 10\n",
            "Train Set Loss: 40.343971252441406\n",
            "Test Set Loss: 40.98680877685547\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.8515625\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 60\n",
            "Train Set Loss: 41.8657341003418\n",
            "Test Set Loss: 43.35110092163086\n",
            "Train Set Accuracy: 0.8671875\n",
            "Test Set Accuracy: 0.8515625\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 110\n",
            "Train Set Loss: 41.105201721191406\n",
            "Test Set Loss: 44.139747619628906\n",
            "Train Set Accuracy: 0.890625\n",
            "Test Set Accuracy: 0.84375\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 160\n",
            "Train Set Loss: 40.814388275146484\n",
            "Test Set Loss: 42.58568572998047\n",
            "Train Set Accuracy: 0.8984375\n",
            "Test Set Accuracy: 0.84375\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 210\n",
            "Train Set Loss: 40.25252914428711\n",
            "Test Set Loss: 41.01683044433594\n",
            "Train Set Accuracy: 0.8984375\n",
            "Test Set Accuracy: 0.875\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 260\n",
            "Train Set Loss: 43.58517837524414\n",
            "Test Set Loss: 41.87998962402344\n",
            "Train Set Accuracy: 0.84375\n",
            "Test Set Accuracy: 0.875\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 310\n",
            "Train Set Loss: 40.557403564453125\n",
            "Test Set Loss: 40.9129638671875\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.8984375\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 360\n",
            "Train Set Loss: 41.467735290527344\n",
            "Test Set Loss: 42.04175567626953\n",
            "Train Set Accuracy: 0.859375\n",
            "Test Set Accuracy: 0.890625\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 410\n",
            "Train Set Loss: 41.850399017333984\n",
            "Test Set Loss: 41.22121810913086\n",
            "Train Set Accuracy: 0.9140625\n",
            "Test Set Accuracy: 0.9140625\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 460\n",
            "Train Set Loss: 39.3553352355957\n",
            "Test Set Loss: 42.03059005737305\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.8515625\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 8837/10000\n",
            "Test Set Accuracy: 88.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DpTsZZLmaB4-"
      },
      "source": [
        "## 4. Results\n",
        "### 4.1 Plot Training/Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yw9hpEi7aB4-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "e6e1ed7e-02cd-4ae1-d2fa-4c0969032a63"
      },
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "plt.plot(loss_hist)\n",
        "plt.plot(test_loss_hist)\n",
        "plt.legend([\"Test Loss\", \"Train Loss\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6ww2lt6paB4_"
      },
      "source": [
        "### 4.2 Test Set Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1KZ7WVqhaB4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2640be6d-c7a1-418f-f929-694b8fc94541"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "# print(batch_size)\n",
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  for data in test_loader:\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # print(images.size())\n",
        "\n",
        "    # If current batch matches batch_size, just do the usual thing\n",
        "    if images.size()[0] == batch_size:\n",
        "      outputs, _ = net(images.view(batch_size, -1))\n",
        "      # outputs, _ = net(images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "    # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "    # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "    else:\n",
        "      temp_bs = batch_size\n",
        "      batch_size = images.size()[0]\n",
        "      outputs, _ = net(images.view(images.size()[0], -1))\n",
        "      # outputs, _ = net(images.view(images.size()[0], 1, 28, 28))\n",
        "      batch_size = temp_bs\n",
        "\n",
        "    _, predicted = outputs.sum(dim=0).max(1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "print(f\"Test Set Accuracy: {100 * correct / total}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total correctly classified test set images: 8837/10000\n",
            "Test Set Accuracy: 88.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0mLwBng9fhkn"
      },
      "source": [
        "def Binarize(tensor):\n",
        "    tensor[tensor > 0] = 1\n",
        "    tensor[tensor == 0] = 0\n",
        "    tensor[tensor < 0] = -1\n",
        "    return tensor\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#     # initialize layers\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.fc2 = nn.Linear(64*5*5, 10, bias= False)\n",
        "#         self.lif3 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize LIF state variables and spike output tensors\n",
        "#         spk1, syn1, mem1 = self.lif1.init_stein(batch_size, 12, 13, 13)\n",
        "#         spk2, syn2, mem2 = self.lif1.init_stein(batch_size, 64, 5, 5)\n",
        "#         spk3, syn3, mem3 = self.lif2.init_stein(batch_size, 10)\n",
        "\n",
        "#         spk3_rec = []\n",
        "#         mem3_rec = []\n",
        "\n",
        "#         for step in range(num_steps):\n",
        "#             conv1_bin_weight = self.conv1.weight.data.clone()\n",
        "#             self.conv1.weight.data = Binarize(conv1_bin_weight)\n",
        "            \n",
        "#             # cur1 = F.max_pool2d(self.conv1(x), 2)\n",
        "#             cur1 = F.max_pool2d(F.conv2d(x, self.conv1.weight, bias=None, stride=1,\n",
        "#                                    padding=1), 2)\n",
        "            \n",
        "#             spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "#             conv2_bin_weight = self.conv2.weight.data.clone()\n",
        "#             self.conv2.weight.data = Binarize(conv2_bin_weight)\n",
        "\n",
        "#             # cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "#             cur2 = F.max_pool2d(F.conv2d(spk1, self.conv2.weight, bias=None, stride=1,\n",
        "#                                    padding=1), 2)\n",
        "            \n",
        "#             spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "#             fc_bin_weight = self.fc2.weight.data.clone()\n",
        "#             self.fc2.weight.data = Binarize(fc_bin_weight)\n",
        "\n",
        "#             # cur3 = self.fc2(spk2.view(batch_size, -1))\n",
        "#             cur3 = F.linear(spk2.view(batch_size, -1), self.fc2.weight)\n",
        "#             spk3, syn3, mem3 = self.lif3(cur3, syn3, mem3)\n",
        "\n",
        "#             spk3_rec.append(spk3)\n",
        "#             mem3_rec.append(mem3)\n",
        "\n",
        "#         return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
        "\n",
        "# net = Net().to(device)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden, bias=False)\n",
        "        self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs, bias=False)\n",
        "        self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            fc1_bin_weight = self.fc1.weight.data.clone()\n",
        "            self.fc1.weight.data = Binarize(fc1_bin_weight)\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "            fc2_bin_weight = self.fc2.weight.data.clone()\n",
        "            self.fc2.weight.data = Binarize(fc2_bin_weight)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "            # print(spk2.shape)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "g5y4NZAgaB49",
        "outputId": "68e0e0ec-0a40-4682-c014-a17fc8258d23"
      },
      "source": [
        "Old Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ghbg4Ga2fhkq"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(4):\n",
        "\n",
        "    minibatch_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in train_batch:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        output, mem_rec = net(data_it.view(batch_size, -1))\n",
        "        # output, mem_rec = net(data_it.view(batch_size, 1, 28, 28)) # [28x28] or [1x28x28]?\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "\n",
        "        # Gradient calculation\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward(retain_graph=True)\n",
        "\n",
        "        # Weight Update\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(testdata_it.view(batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(testdata_it.view(batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "          train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hDQg3UsUaB4_"
      },
      "source": [
        "Voila! That's it for static MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Rh7ZwFs4aB4_"
      },
      "source": [
        "## 5. Spiking MNIST\n",
        "Part of the appeal of SNNs is their ability to handle time-varying spiking data. So let's use rate-coding to convert MNIST into spiking MNIST using the `spikegen` module in Tutorial 1, and train our network with that instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DYGblNEgaB5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "006c8bec-2f78-46e6-c8ef-3185c0d014cf"
      },
      "source": [
        "from snntorch import spikegen\n",
        "\n",
        "\n",
        "# data_it_sum = torch.sum(data_it, dim=(-2, -1)).squeeze()\n",
        "# data_it_tmp = torch.movedim(data_it, 0, -1)\n",
        "# print(data_it_sum.size())\n",
        "# print(data_it_tmp.size())\n",
        "# data_it_tmp = data_it_tmp / data_it_sum\n",
        "# data_it = torch.movedim(data_it_tmp, -1, 0)\n",
        "# print(data_it.size())\n",
        "# print(data_it.sum())\n",
        "\n",
        "# MNIST to spiking-MNIST\n",
        "spike_data, spike_targets = spikegen.rate(data_it, targets = targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                      gain=1, offset=0, convert_targets=True, temporal_targets=True)\n",
        "# spike_data, spike_targets = spikegen.latency(data_it, targets = targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "#                                                       convert_targets=True, temporal_targets=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bcae4abd1c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# MNIST to spiking-MNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m spike_data, spike_targets = spikegen.rate(data_it, targets = targets_it, num_outputs=num_outputs, num_steps=num_steps,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                                       gain=1, offset=0, convert_targets=True, temporal_targets=True)\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# spike_data, spike_targets = spikegen.latency(data_it, targets = targets_it, num_outputs=num_outputs, num_steps=num_steps,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_it' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xgRdm4jRaB5A"
      },
      "source": [
        "### 5.1 Visualiser\n",
        "Just so you're damn sure it's a spiking input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "geVqzyksaB5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31db8f26-0d3b-4896-c331-1788487d1079"
      },
      "source": [
        "!pip install celluloid # animating matplotlib plots made easy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting celluloid\n",
            "  Downloading https://files.pythonhosted.org/packages/60/a7/7fbe80721c6f1b7370c4e50c77abe31b4d5cfeb58873d4d32f48ae5a0bae/celluloid-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from celluloid) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->celluloid) (1.15.0)\n",
            "Installing collected packages: celluloid\n",
            "Successfully installed celluloid-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PbLMA0pgaB5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1be4468b-1a39-4e6b-ba20-8a4ad23a8d7b"
      },
      "source": [
        "from celluloid import Camera\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Animator\n",
        "spike_data_sample = spike_data[:, 0, 0].cpu()\n",
        "# index = torch.argmax(spike_data_sample, dim=(1, 2))\n",
        "fig, ax = plt.subplots()\n",
        "camera = Camera(fig)\n",
        "plt.axis('off')\n",
        "print(spike_data_sample.size())\n",
        "print(torch.sum(data_it))\n",
        "for step in range(num_steps):\n",
        "    print(torch.sum(spike_data_sample[step, :, :]))\n",
        "    im = ax.imshow(spike_data_sample[step, :, :], cmap='plasma')\n",
        "    camera.snap()\n",
        "\n",
        "# interval=40 specifies 40ms delay between frames\n",
        "a = camera.animate(interval=40)\n",
        "HTML(a.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 28, 28])\n",
            "tensor(13373.0117, device='cuda:0')\n",
            "tensor(100.)\n",
            "tensor(100.)\n",
            "tensor(94.)\n",
            "tensor(94.)\n",
            "tensor(100.)\n",
            "tensor(99.)\n",
            "tensor(95.)\n",
            "tensor(98.)\n",
            "tensor(96.)\n",
            "tensor(99.)\n",
            "tensor(107.)\n",
            "tensor(101.)\n",
            "tensor(96.)\n",
            "tensor(101.)\n",
            "tensor(106.)\n",
            "tensor(100.)\n",
            "tensor(100.)\n",
            "tensor(99.)\n",
            "tensor(99.)\n",
            "tensor(102.)\n",
            "tensor(99.)\n",
            "tensor(103.)\n",
            "tensor(96.)\n",
            "tensor(103.)\n",
            "tensor(99.)\n",
            "tensor(89.)\n",
            "tensor(101.)\n",
            "tensor(96.)\n",
            "tensor(101.)\n",
            "tensor(98.)\n",
            "tensor(98.)\n",
            "tensor(95.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAxem1kYXQAAAKuBgX//6rcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MyBsb29r\n",
              "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
              "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
              "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
              "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
              "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
              "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAaMZYiE\n",
              "ADv//vdOvwKbRZdqA5JXCvbKpCZZuVJrAfKmAAADAAARsG58lw15q9IkAACtobhz+EtXgAGbPfnA\n",
              "6vBq2y4KD1VFSYr8QiGU1RZ6il6SV2xj+fxPL8Qg2QV8kwhIQBbXvCJ+J3DrBNqI3E/luFSKn3yn\n",
              "UL9a4OYVcKYGaf0ChmqhbGwuqZmOHN+pVNZoeCzdM9qTD2+4yGNEP1VSN02oRxKcmbiqi4Dxy1DZ\n",
              "G4FShj92Wg4YfllBP16upXOrNofaO47gJ5navf7+lGmGFQjufvpe4GZWxSNAO3dIeXyRitPo0hu4\n",
              "SXAZrSNnKKSqBUrWxbjtDSeqBGGCC6NSiQICxEHMaMVqg4ZFIpNR+pNfHvScFwVkdziOncyeGUNx\n",
              "2cq6unf8amdbmXT2ZlT//vfIgLbY+c4SgDHKsLtZRuUyEJtu4WG/esyJbxASlWUkbvG/OUDWyBuc\n",
              "aynWYaJoNa94lwsuRtddSC4UZL9iEI5qeQr0WAIq/0hNFJMytuVi5mb4UTXffQlsnqbgpNlu9Rer\n",
              "tOj9XqFz+QXzLLaVWTG9dgw6nNzOr6WiLkC8t7KEu1QYFxWo0YYEXcsXzJnCA28M8Ya0XngRkuhx\n",
              "tVYoRRik4s+VhPtU1/BqoqNqsoyOcLkx4NlCQ26bwpG4onImfV57344+/LHSXK3n0+p8+gYRHPLA\n",
              "aAYbxKFqFxhHYV83v1yKDlbpNNKc07+iTPFsejMGErdR6K/oTqeYhI4ptUHhw3LTmyIh/DTaSJE4\n",
              "4G+FBx8QJR+MW474g5lODn782xsHEo/FJcbJR3svmlXhVarX3X4Toj/g3jTc4hg+p5ZvrhPJOUPh\n",
              "8dfAWoYsJAgNQgXdML9ImBkWsbknbfcbbGEu29M2VKnA1umcczsttjwj+LHZbvqxI41VE/qnb1S3\n",
              "f/i4xKVFaYb198KLUxM6haNcOYeSw1sJ3bLXlFkMroA0eEqQy3dSJFL6OIlI8TlqZpIxMAYLMJGR\n",
              "G2kJyibD0+s8g7E7WAuFnPuUhixmfyXCgdhsOMD3cTpzH6g/nGuPWW3u4/jkkaXIrVKMTFMJMKn2\n",
              "0Fh5OkCl+IV/cKM60VOqcGu8Nr8xJCBQCJ9TgR4FA814P7yjiuCPWlEfJq/n4Jmof0ETgRS6qJwK\n",
              "Ntd10jBp8XszItaYwORH/r1ijAHRSUR6uw7w2ge/4DSWW/RboHLOD01L+3OeHspFanUUPY9tg38E\n",
              "A8bJZw9+aWwvgA4QHZlsSVr8a3E+VmKciaStG5EAVkwc8M+CnjfQ/vOx50JApWKjZPj/6eVGGXAU\n",
              "uDv2ereVqqaRhQV3E1eNA/KJK3ao/RG3OVapfHN0mWztPt3RnbvnLPQvgODDPvwigIokbKlvM+sw\n",
              "Dye3B+4gJufiShynaBnGwPku9lUcAdM3an7lLdbx1KATjwuDt+P2BlSGJP4zdWD/eIRgcEnSVM2o\n",
              "L6x8ciuyXxmgUkO3oZBmw1xLk+vH8z0mWqoae0rOyNPFRv+QjlkbRisPntGCxw//tNCJc18wCwn2\n",
              "tMb634T6jVWw8o7EunJpIsZ/pf5cOrvZBcU2B0kQqHb6YEiWypoad97lReEhSsLYOVFX85VSMVSh\n",
              "ozRVDtws1caRxfal1AN8NyF2dZvr82Knu2VjADqAlpxQksUq0XPR6F4WH8DDSTrbntqvGY4tHFR+\n",
              "Oa3CEsQb14vWD0Z1SRhZf7wZlrWhmcgFGBVIPV4N7smUbKlgxKj0brxYB7XczVP/g/mDe+b6Seh8\n",
              "UnjF1rk3kmnvd+fs0m86O6500eDczIg4rzLw0VhKDOxaJQoT0RzCxlvD6vQBC1GSL/T8yDDFEf29\n",
              "uOvzr8JBpGLN7poM5rmwUI49qRzMw9rDmt/+DmReyuiBG1LS8zacFi2Dxi3GoIIenCfTDHl6csqq\n",
              "j8KT51dQGSodKRe3KLTnNU7NvjA7KCCNc40JmGLKnIibamaKrK5Nzzf1VV8sN3/xTJlEe8aelRF+\n",
              "wd4/yakT7IsbTp0hQu0jwk8nmmIg+uuH3smWrRDtH50dDL/GxFN5fzw0Crdpx667KjzekzAJ2RNz\n",
              "cgAC2qACsA60NI2mHqvYni63eeryPdBndCBLleihf8A+LndOT3/6PTM+JoTcsqYegPncEPUWxP82\n",
              "ILeZJwkhSt4njnl1Nq7JKK/SjyMYNk3uvhVi4isroffraTxc7tYcd+lDNEHfp7Lgn9reW0vJsAUe\n",
              "AfeVDU1bCQxF7N3SuAAAyEB0GZEAAAL8QZokbEO//qmWAFbuq2m9y8j288YIb6AC6Vyb7ybHqu+r\n",
              "g/kd+UILetyO3zN1Q9mB67s+vYOmLRQlRA700pb8XSGb2unHgJI4OITejy+HUrHf8plXlXBgS4RW\n",
              "HMYabmfyJU8zC8W6NQyqtDvCZpEBuHPH0s5QjrHo2KkzffW4OKC6CGDhj4/iGeo+QmsSipXTq7oi\n",
              "iArrzkuo0k50tzfZx5d8btfyp3WNO/HMJXh5Qi4NsZjW4IJqLQtUPGbeXms7+g1Fek56JsKDSSIb\n",
              "J8cF+79g2547MAslWdFqasFDkS28E8ae54HTLJf7GltvGeEeAYfeF5oSys7tckAgPRwp27td6JRh\n",
              "18hXJnFfN87bzV3ElXZ7e7rHmZkTOFee2N4fOhLKLNpNHVB6CEBBIh263qfX/hC2pJTpjnYJHD0/\n",
              "nG67O4le1xLmV4Mxj7zqdjkpt3mTk8ZklXvV0jHOCmI0gZTbuoHHoMT3kuJ6I6FQN6rFCo4KJpLp\n",
              "WHUauoCWYFZ1rKEZUEEFYxFJsGQjnk8B83lomXzXefMaxO0kXTLzXxm1KSwIVQe1MfJq8dQlriuq\n",
              "hkvJl+r1aWInpSaVh5zEpw4l3u9tkD1lmf9wgFiUdexK1I+ca1HfbKVbnSecUUXYzrcMRWEBzq5t\n",
              "zuF3eiznMCIcQgJtC3HjHf4ktpuU+Dqwdr/z0awSvKm42+ZjfDtv0qrVt3ppLzayo2roHyUgzemx\n",
              "2qdMbPt34j2jgZjHDTTd6uQGb0vyR+Wx9py9QjTdiPIWfjjqTGKWebDEd7v7xYclPJdLfpQxs/0H\n",
              "opAX/PnYFAcy8FCn90Qc+hIWVFqd58CQed6SMm2Lp9JckUq9HxtoQP7gRKu5KypDxSQtmUQS0iM2\n",
              "v1cESsoaKGykUAYxt+MFHNrklDbKDGRQxVt2IBcsG9ojnlJw/Kn+3viNoKG0Wvfk3zuHtAeocvvd\n",
              "8JJJ6PUytfEPLAAhCa4EcGpn/sCPd4K3j4Q20EXDllyegOiUTVVtwpJetgvru0gAAAFSQZ5CeIX/\n",
              "AGnAefvo8+fVrywCM1JdLoC+pb4BeqrKwKX2ByYdeen4ne1wlqioaASQDqwInKIa2hdU+822w5g6\n",
              "FSRUUZamka0aGgbYQlBVZmF9F8slmkjVRyyW9/ZgRlpyQsZ4HF85L5NEaMHzY/AoUzr2jkPCGA5u\n",
              "eln+uwAhGa1rAOWhxX7kC7SxI5zJ/glMWAH/1Gk/WllQ2CTzQ6KopzpL1S0XEDUP3QM42+lDV7k/\n",
              "0ZsN8p8z+bKydgj8EaFbkgfRI4/40lTF8cpnnLWC6xmniz56CpvNzaWR4mcEsJxAuxA+LauO1hvN\n",
              "800onioZ7mBKLbEnu6B0Vc0tI2dOeAnmg9Iz4wstcHn3UpIq7i4PrqfDB7IrmrjYMrk9YuKjE90V\n",
              "+Pq7Xru1W4qNGLZedf/iwx8JhUM7UydZdpinWTuOC6YahJZtu9mhPlne8iBOnAkAAAF4AZ5hdEK/\n",
              "AIbt1d/S2eKrGqPUAJSxctczGkBiaq+orlFNOkYFly448rN99sLY0BqANurwcskp9IZbJ0SnTF4J\n",
              "ZsC/tXSiF5irOaAEGnbAB9eQ8+MIlJVWJJ8ouVWF2VbeYPaFQVzxIo4p9czxk1wA9RNhAq9MoeG+\n",
              "wbydezoNhCxi5DaPXuh2YU2R0w3w4aWBrCnvlOthYZqzDvALMnUkRQgJd5h3xX8Aslc8jJua5SzE\n",
              "/alZcOWh6mnZP8eV3zl82C0uGlxtii976OKO0hNv9EMIXNSbEtvdpajIK5Dj+00lmOssTux//wbD\n",
              "O7PlUksrLy9uSVKLf5KT2jiWZv10CqoUb4i5s+yY7lSNupv63abCAPg0L3qXgTV/uRnXVUt/33kn\n",
              "gBO86k/gT7sMbyuQ8zzD5ADJEkaT6vCh7SgRzwYeq9admEKM/sdsSRgcpYX5lVEXKnbB//xlmB0q\n",
              "cHHqFjN8E6ylqA0EETZ7Jsx8AVT53rBYKIDbHgAAATUBnmNqQr8AinSOq2ADXd0kiQY8vEcXUgdc\n",
              "ZGGqKOEtcuugj/Opf90fxk842p/Cz+nl/PzA3Gk97KBlvtONJzn+gxAXmzbfHPREveaA0Y7cqdhJ\n",
              "92A3fb3vmJWEm5gAw63XihfyqF+F8nNIpGA9LzoISiS9NWOpmN/s0og/hKZZF73qjQNtYZWdvAsB\n",
              "at2KgH5GzGtGq7P666dVsphr96yALTk6vx8JAg/JODT5qy88WrMHgbBZD0t8oBUqfts/hXLvbVPe\n",
              "2zHRB4FzQz4JB5dhYnD4TP8bTH459mSIC+tih+D7LV3FcPXFoWsjA4efaeFdAzj9SXr5WRsj1N/p\n",
              "8pnabcVpmXmNg+N0DFuRldEkT426vVimh7mE2cqtI7MucEHMQ9kB4TfAhZLJWVUj3uApPvueueUA\n",
              "AAKzQZpoSahBaJlMCHf//qmWALHnP/wcRlASrFCuzVT5tBT51Uzplp0ggKHTGyND4OjSQuiMV4O+\n",
              "7TVoL8pwcc21q9/mB/XiUwDBk95aFTCGgwukBtCMrD8CuU/CKJZuE+c7vMdnTx2dd9Lv66+HsTKO\n",
              "IgEo/4Mv62tfV8G/zvbzE8Vq/dI1tMzrcEgcbv2UT6Cir0HEZoHVyOg/Ss8fQi7UaFsXGr0H7ZeS\n",
              "UbGure40VI62mYm3azHVFWLKlca8NU8eJQTk5lHKaWM3re3zYKjn+eKmq44iEIx9vQXyzjXweT0P\n",
              "laWiePOU/GeXmLNnVZuLEUzpEyZWeNC7Eoa35Th3089JFSorE+EQiEJeLePzyJyCbxZ3ZsN5j/Eo\n",
              "Ca+YUqKQfSuxdj+3KcnuTxH8RrQgBa+SBEWgO9Orz2OUHDLidkiYmzy4fqotPv6VrDIWPgssy+Id\n",
              "BC3ah1HjknCraPrOInpoTr7H99efD5qj7rOSVuoO6I6VFU8OWShzu7CmbieXmytAkHI5SQsMfghh\n",
              "O/HfS6Ew4lXjVTknKL3za1WERC72KG+fUubdea6K+SaS8Tw1rW0Co/2Snugv+gGKOLkHH9uDxOn2\n",
              "jpSvGQx1ectSFGzgXV5QDsTEXNl28YEfAXu/ZFxsHW95nVqSZP+Na4DRvTK5N+97gxU+T+9Jt3XJ\n",
              "yOKewWHcYK8OBecIMzEfx7pomMlIwkQB+KbqibIFOpMX8Fmu+lUgEt7pO+Gd1OCY853zO1SFekCb\n",
              "R5MxnaerjyVOgLmJfncyK13gXq5HUDVdZi6FeIxkYvaRpvZbLuNdsMoC9HTUgTdLuBgsNZHLtAyu\n",
              "4Zi0ZNHdLpWSNZcyF0wEdgaB0Hl6U4+X5BiHGTgj3Ug3YZuwNrxSD+z83/9qotbLPL+BjTYKPkg+\n",
              "7HG6siEV7YJYpQAAASFBnoZFESwv/wDNhm202/vcaoT6qXjiUQXuj0P4IrEDdraIIyBXiNOsNi00\n",
              "B/lqhqTF1thQLl8y28QXVnGBPDeYm4vnHk4xACcvhjlpkKCBv2WXKpfWBU2r2e1IAAOxdugQuV3U\n",
              "77WzHtccDk2fGU/Ed+PAE+FgGKRkVBze7M2RQ4rsvC2zDHM+BcxtP7i5cUwxj7KJZH14+w+zDhnh\n",
              "AxFC3B+Gc0Gx2uNEpT0zfqzmrSSGqofm9j9THi+p+0P0hAOmBGVAjLsIw4y71rbSFRofMNeh0RQD\n",
              "jHC0MT+uc2fhNRsiJ/ApurGhJat+2GuRiY1uz0Tncfcc0sA9EHzhQdrYcp5WzNI0caEIIcvVs8aP\n",
              "DAxo/XuFbvMiWMyQJxnWRIA5AAABIAGepXRCvwCKxF20NABetLACv4wqk5fQLijN1qP/knkDT+Vv\n",
              "StgxvQzXaNAUa2TyxQv5BrtE2fhzDcaTkgKzr5/nrS0u+D45rP5Dl14OfuNEUxG6h/PoBLUCK1DM\n",
              "FykdiCHtOOPD1BqAAnyQE6LhTHudrOyN9NfPp/uuhsSjlJqqcIjd741W1TFlwonUq0GdacsrC4V9\n",
              "IF2pcqKTVj/zyhwrkynZyRPYO78HQ9bff6KByFZH/8VD5z3DKsTL7TAljWMKXhjiUKspb4jmDlXh\n",
              "BNL2thFtikr8ovr8/LlwCfZGSTqoisP1PGsDoHrQDvBjeq6PhuZo3uaVghbIobRJ+ITEN2QL8XZX\n",
              "4XdspygDBGiNX+a8Mp+TbT2QmJfxoOfBgQAAARIBnqdqQr8Aio5MjWe7i+vnOJ28V1PT8QAb1jzJ\n",
              "46dm3ThT7tADhJR22x+6/4Rodp3aj4H+bKzoKDBbcU+2766gkxJTmbX/A0bsFDDw+Nrgbq5u0mk6\n",
              "W+jTpvgPvvHHPkidAbW0FRnetRSf1A1xFZZq8S1KPz7LvfCJolnSkWqBHXf+ALvwIiH69EUkgKs4\n",
              "npy4xP5nradJT321lU+M62IYHDnjOJo+2FMjRK2KGSGjd7+cTqHI9E5su+fTy5cAibx8xAD5sUy0\n",
              "GW4/A+MwNdXCF3kJNVwOQGJcPwo9cRtllRW0k7Z5B/bMu6CewxIjzjyl3P/4abaSTIW8B94A5BZY\n",
              "QKW0/OfIHo54TOU7xOBcloTWAAAA20GarEmoQWyZTAh3//6plgBUxclbQC9szJWYQAWiXSqKU3xc\n",
              "wTllxJuSGWP9mWEIKugy8KlyMplnjxvuA0z4/8Gfmi5vUgevaql1rjUgnXIqQxlqvjOp13E6SSAR\n",
              "fhVUrtUhlGTAPivbW8yCNxuaQTBHBfg5tCA9UrZaJ6eMRNMaIa+flmGvTHt5rFBdf3C9eUMzDPQQ\n",
              "CkRqp4VkLLiUG/AQzGnA+tFmWch/TXTkE0DfVe/pWFi/3Z2CiX66PjbUahAt18zPVI10hOH91d70\n",
              "MrFzVNmvb5WjH8YwwAAAAXpBnspFFSwv/wBoWl3Kxa58rpRdiEADhmeX8kRt1yDh3ylLf8kQns+2\n",
              "dgwE+T/GT0rqyDCxCOAdS7BToTYcPZdCafns+bVUDg1Dss928LjmZvi8eJnkn2cbOiacOqiYqcyF\n",
              "x+1gfQlBLPNhvCqpUoJlSd4YNIqAwcq6jAdV0xgXd5uzArrvYP5io7j86hD2bKzvcxaXd5OwYXSU\n",
              "EqzaLt8IryPH2EPEwn/+KEZa/szaUIkwX17d5heRGOoO+nm5Wi+J7Rp301KSWdto3y68iI4QhyD/\n",
              "Ra1S/OTF58tZmAZqpAPcTiEWeciHEt9KKud4obDhjMkQrWZGgI87oxTVb/2iCDigtK7Y3Pd/YcIE\n",
              "COFo7n8nmBbEVrChpb8QnK87J1IOHKwrpcVg3eCIuqvgilbiA+ZPthjJqpBVBp1lBWgHx9gffMKN\n",
              "uFoFArFmIeGA+KNwL4PpbooJEZsQSEVVdl4K6J6+qKjJyeMC4AP24qA32CmBpf/v0y2oNaEAAADk\n",
              "AZ7pdEK/AI74MWmmPT31eZRj9ABOOhVAnEQGH/0A7VARgwlDaJ2u0J101IK8hJBw3a/F5yAbvYNS\n",
              "7SPERBkQkkiUDpZgffndPxLYfLuGAi+qYqNuiivFTxvcVrdccR/UdngFfT8zvZhKP/csBNdvo6U1\n",
              "f60Qp9TyXtqhFrnNwbp5ETdG7yoDM9ks7b7V1b1tUPhyaL4KHEXZa6jpb7Vp1fj6uk0rNAuQhx9X\n",
              "JIFwiFaAV01BrasamYbJf/vOkWQwob/Kv4NRtd9glxFLkFPdtB4kgnI5/G3hKqjjGMD3qFy2UCdu\n",
              "AAABHAGe62pCvwCOyG+dm8cazb7wAHCm4mNBOcgErLlPsLj+X+hauQVBwbbSz10OxzRWOtUf3C2D\n",
              "xbPgPI2f9Evvrk3jUrP/CdM6wc8k4k9HwsBF6iX/zUPzylpxkPXbQRB/8fExCjpemNjvXiqM347W\n",
              "hpQKgpH33jk7pBfzUNCQE+oSv6QmIX54w9QC2rYDrny8akeZuFMyxh1HDrielfJYr6ND2VeV+VXo\n",
              "G/wlXqqstIJV6IkyoqCt2I6FQE+CCc/HsTGnjSFWv8BbAwRsD1i53c86e7H2bbHdoVt/p5MTzZr3\n",
              "Hyy1COfYFxDny6ajVNgR1dV0KkhaBvXWNnIGfyZegQm1UfCvfx6Abmb6xCoBJCWxkiM0E/0IjH6Y\n",
              "SAykAAABxkGa8EmoQWyZTAh3//6plgBZv7OP61jzVD0uqRHAx5IlcStJnJfJ+y4NSQAhBHim+zzx\n",
              "cd/ngUwN525yr/iQtbGF4pDX3dfRAOe7iVCvVbVTNsFsvYxWgJHOLGVcuZfhXscYKwvhV10CjnFG\n",
              "1kBQ36446ERxisegC7Kz8VE5sp9t7Iih0jf7KSz2ao6wHOH6vOfwp9H/l2VGkFNDdwbxDXcD4QAB\n",
              "Wcu10RZtXjJGgBkPD5cpdIM5/FNrWv4CwAwAAAMB+/ho9tkt4KyBX1kbUhrzManprvZ1+36snmCC\n",
              "XTMLvc1OjQQ0/F4xFcp9cn5IMeoMb47wjch/DiCuUr3IjL4zqut9pZRV69AgQK0u788TqUh6VKFO\n",
              "9DBsI/y9oShc09RAH/7TgAUcNwgEk9oRtU2biy6bsZ/xOAbBiVyG7U0ujesVnuK3DjOZIPVNzBBR\n",
              "bq3EkaYBFJhuE+sjnXmsl3wMlrpTL1ZyhRBigh8OluGdSTP23EI5B8LbTDC42KbRu5dysDxoflD1\n",
              "+eYpJOppWvGXAo2XDBOsNeAUKrQHE2nGHs8O6952EJPkquBfK+u9Fu3VYcQBRwtW/TQV4zRgquwP\n",
              "IxBRnlUAAADvQZ8ORRUsL/8AZxIxH8WTFW8lafpovqwEbFV0GyfD1WwLHDuFSrb6w8nDs4a+slY2\n",
              "XFvnM0i4Hvk8GZwtK1Zwug0oC+vwcbWJ0264TKQBnXuVbk5Kg0mQV8V8HpbvdbKuM0TZzWTNt8UN\n",
              "IyJdfT2iB3LGm9iPZy4xEpTzho0PRbDQrJReklZ0CnEx0iflJ/E1vafW3Io1a5DRFogftU555Hm0\n",
              "vn1gicudx+G0CRDJbfZxrF23tQhGiIYfZHJh4AnSpxQaxI5PdhnQlejmg/ILmZCPVQhX7vUFO35a\n",
              "bvARZiMcgkKeO5r/vuz7zMMVRQkAAADGAZ8tdEK/AIq6dS+C9GovZxAByny+2LmB34UdS8bmy82y\n",
              "94XjPGZ3cth3UncCIfiGfDZnDVPKGLaYdrQDpr/S9sjiqgtF4aZMDDtPaxytF/OKPKnvDOsm5SrH\n",
              "4BJ7UygYiEmPOF1oSpJ1Vx88aBpgaerLNhLF13LqDLjmMVETRf5UBWzx+VlAb+GwOCXZoSVF2ndi\n",
              "ZLgs/mF4Ar0nKhTYCWQN/4ONl3Lcfo8q9b+S0IANobRi79/H1dzZa7EJ537fFj9Rq9u5AAABqAGf\n",
              "L2pCvwCKyHVd1eUTrgyyc7LWsqEBfV7AAlSSqSw0iAw/+gHbRhqSzLxu89O88S5ThCijnETseL50\n",
              "9VBN/nHi90PJDQAM8QJho/yXp262kTqI2w2vAlkWQVscQRgmrSLJFRxAmK7K4Jjbju2hmzG70J+X\n",
              "f6WNJ5bN+G31JNQ7eRnDiKDh93MR0aIebIHhsQfyGSuIO2BkrEMuR+3z7spD6fNhlrN2Zs9QZR6/\n",
              "O5RIxb0s8nb+gBV8GULEtSQ8umqK8SNOJow5WoupcFb337kEZg5nSySxuTkPEYDtn95kbRmgyt+X\n",
              "rdFHKV7vUt0p+Yy1VOm8iq8DPKajgnArJdrZ2/rKKnT7ZsKJ57+MAHquZC66fwxtg/kmdShjT7NL\n",
              "xYrKCtj65BBvfII6Db6WnXSjz+MUa1fEDX0tD4V2OJY6uACoJb/ddWj4yDV7vOWJn6Lh3Zd/NzR4\n",
              "NKj/CgqSkYUfIt0MBosEamWEYZzV27siP/0uAX0LbOh0idYIq31dcqPmmIUae/V36sATjA/FCEEG\n",
              "l6L/gZU4fNXTXRjQZNq0HLBk8y5YsCYAAAF1QZs0SahBbJlMCHf//qmWAFcFwlOP3FvVFwAYXa47\n",
              "FJd0a1UdW9//ZWueKBdkDFj9EAKhOM1NPXaOoICPNZ5lhFppLKj1qt3gUfHrjwAn1/350K5ZDatp\n",
              "0ST+Ey1fvsak2xxX5ablCZUQLnOTSnJ6RiTqtDDpM6qLA7O4+w52Vax8DkoQD830sShkKIsf0Gro\n",
              "bZiPg8D/qEUotT2Go39j84WYByaHarcDMB71JzcS/Iccn3tIRQN2bJcGxge0gqkY7ox6ePTuAOrI\n",
              "qnMA1F+K7RD6XIi3CbCyjy/nCVVsyq1AXLW6/Qqxn5cRbo42tFgkAr/0/1vc4xn+Z/SLnmt2qTTb\n",
              "hViyIxROq06Vp3uudz72yY73+5lM0+DJ42/gZHcY8tGCgZMslVfCnaOJ7MUOJ1ROKpnbwZXHHPx5\n",
              "NTk+huT2tPMoea2hBTOHvwqOC1/guJtTk9HFagKNhYzH+AxyTNYe416GPEliH/047nthK76amRe0\n",
              "lgAAAThBn1JFFSwv/wBnFL+nfKnq6yyxK06pMvQtt+Uuqzbs3afdQ6wjZzUXnmFk5Elz4+bpvPKO\n",
              "aSntgAVH/fqbjOTsjzImJTl0Xext+s8yQ7Z4hkt9KDYrqaKkujq03CSHiKme5Xek/HvvwJTuFc/i\n",
              "9cyHz6gBX69DvX2pFsVTWFHdVEeo9lHqj+x/f3vx2JPjoi4IymBdOpsCr10W5wnJQywdSZpezFaJ\n",
              "LLBNXqQx17TtHvlyLtEz1KCfJyCYytcVSmPqEnv7qwxM1pae3M++B64m0hgpuVXwkDpmsJTObmew\n",
              "6NDnlrRPyc4yB7dTKtQIx6cSUiNmUrL/zGrYOWoLK/xMa6FBLgHYKqWDhoHx8l112r5ePeBG7Zx4\n",
              "hZeA3e8kvqqSglcC0xjBvDSGOaLvnt/ZE90D+NnMH8EAAAEFAZ9xdEK/AI8nI2vEwP6Pq5nWegcD\n",
              "flUrmAA68GCpLJlBR0Q8bWptWjYvpyVoNigurQvBTMhphDdFygAr4/YBgGpHe/V1xtdGHcd1P6cF\n",
              "Xh/Y40o6DWsC+EhxGzleJOfqk3S6yLF8Nt1aFd92JHm+SPamcwLWMPeZIA+jzIcXdFFl1U2Ualge\n",
              "wdr9T52G0VfGAxosg55WsLRVWBahVD75v0EwJiWyRT6u4brNeMUUErrNV2mzGt2LZTT2lGl1VQS8\n",
              "sMKOL48S573KFH6oRdT52cL5LiRA8YvbXPkTIHpRY2/SR75H6Mw9wFCLXHNeVtp3rRZDM3zyO5Zg\n",
              "Ek3py/DMvz2zBhl4AAABoAGfc2pCvwCPJyNrxLvsdZp1EbQtcy8hPZlXHuh8gprJNDnKgXKK8rL5\n",
              "fXQhaMZBOpe+h8LgxPz1nAFiAOpZ4AiFMSS5WCV3Vm8h6NxcmCUrGfByNL4hI6LdlBlx6CyweAgr\n",
              "B+TIZe70RinMZUvJSdTM2NNZVVDRAiu3TobMxaAW9um4D1/sXmJmJyhtR/33cl/07E3IMikPoYXs\n",
              "HFl8iS4O6Xl1oMJJoayM7P0v474HAUg5VHhJkrUAB9nnW6CO3t9qbECDf1gsViryZHBHR0+xq4cU\n",
              "TQJjzSwVOjpF690yjiv2wlSW9ECqVAjOy72Ir2LmNNv+D99bhL80Fusutv595J3q8p4GzXGD8ihF\n",
              "WrAAykRTMCuv98r9dD5MlLW4npBiDyTrAI8btJIpqCTsb9puRgD3f1sae8XmL03cIvHCucuK3xnz\n",
              "PmDowzrecaDxN1+j9BqpAnYt+kYD23x3WYxJUZzfuASq86WN0ikAV3ZUzXdsLfa/v3iENCxofgrR\n",
              "so5brZMuZA76Qn+Z8F2TbCHE3S2urC1cABpqVJqI7NCAAAABS0GbeEmoQWyZTAhv//6nhACxcyzw\n",
              "HgmoFCiYO2ADbhj/hR3J6Fo/xqNlaN6iuA4bo/qynEaNQCuBpmSjggOBM+N+VzlUAlVWtJutKarn\n",
              "TmZy7otq8zg9m3y1aOKd/l/w3PsMkUbL/o4IQKu1yXdWLwNzrYre1kjsHyVB1577mrfna+m99wSk\n",
              "3j15n/WNyAHoa0M0G7SxmLlxJU1M4pe/tVBNSngz+gxcmxcFd5GpsgkOyaVdotOHJAGdHR0i1jlz\n",
              "JJF5T6iPJDe66lPuCChkze799D/pR19e1ztJfaqih9/7xFlMx7qTKiigO8S7uNO0dnmuM7BdXDxI\n",
              "jBxLHQubGVckjnip0GWv05kGewhxxQpWKhjUJAPBIzgjeMuNKVYAz+wg3OpdorYqT2ECq7iPP91/\n",
              "arpdlCAcCB/mddXHfk+Y+K6EvLuQIa0CQYsAAAEFQZ+WRRUsL/8AacB55T8DO+R89/CMWxVL/hdU\n",
              "CV6B7TxfWjEmLy7tGVJ95UomsAoB7p0bpkFle3S1ee3m3YYkElbr/xqUcX168X4t5N+xfVsQXrqx\n",
              "9e5OayABFEfnPxjjfNzfpUVQ1TvlT4hp5A1DWxCWP5wHHBBAvMz2CcvB+YjvLexOn3Ph6AgRIhT1\n",
              "ZyodF9dFSsaZl3qiuj2rcFCngOCK7ytxlh2pLDew05yhNrFNtcmK9o83R4eY6SlypRdUGjdmgBA8\n",
              "LmjF5faD+g+6H4nwZJBn4PZorjVhQHBrahvi/fDLamwOXoYlGdFhW6UxqsFsqJYGVplC//P0eMnj\n",
              "F1laqKpQAAABJwGftXRCvwCKuYn9FEAHKXjj6hDZpQg+JiQ9DlUYH1TBXcBDMHZt9boJzQoAWzN5\n",
              "xdK/vx/bBjOHlg2RzXnQ57DN3oWqDuhGuh6mMD4oBRLqWP0mHmAAH6ZbCOMd1exjUrd//h0Ki85C\n",
              "eB/wHdgxXmlXxzqW+WF4VkYgQlheyPFX2jRP6Xwdzc4bfMyeRYwy+JKWEd2vPfNkFeogahbIQRYq\n",
              "RLoQ2m1Ugvi/N+BSCL4zfHz40LpMM3UhuR4Zbwd07XXSnE/V4SlWhi0b+IJn8Br+VqJlzd52dkOv\n",
              "JP6LljCgMURfxdMrumYntj4MOA249NiJLuWx+r2A9r4G7fVub3Zs07KpcgGM0BMf4EE/W85jRVP3\n",
              "jjv8QvwjB6FGyXZ5nRSqbch5+WEAAAEoAZ+3akK/AIrriCT7Wg+BTAQBABu2+BacguaV+F2I8PyT\n",
              "YgBsY3lqGBAynaINrZMCFOqTkJHvnNOjsVIV8Ao8QQS+1ESgmjlW7hc8envELARzDZszh577if6o\n",
              "JhBIbpfNfMTI4HgywM2xS+imw81iyM9rsVfDBn/dzO7GpxLU4+0PuzU9YSjJI2upUtZ71ST9e01x\n",
              "+3NJzKVuidZoIrn13OVHxoMTxSt3p1EadIMUSYz6bdHjuTsT2DHwWYXo0iCkWaXrDJS5EL7sGdv2\n",
              "8mpVFwkXJWF0CXcCMRINZdjin8WZAAo5dOyMOzN5z5WeHT5UCuKgWubj5vrvnL2RHYESXH87ne84\n",
              "l971Zb7ktuGfnHsFkJebnUevZYE7kzd8tgmgrnHsgQ8xMaEAAADzQZu8SahBbJlMCGf//p4QAp3q\n",
              "NAXzu6aLh+PhojX9xiTeXUmnxLlkAF68ap8qZLAAsKnBq4yPvRsA9mocf2Lv/i5hbMPTfXnE1MTe\n",
              "HJtKHYKeAbvbYF8z43h9We5HJTTac0mBbF5My8xfIzl254Hbvm5C4IutTqJSjymwiXH1Dwx7PxDL\n",
              "AiS3IaDbSivJgBQoauzyyhoMIS+vYJ8kCQ6kCzBDb/0UKVm98WywcVMzQitlM0uN6OtVz8dcFO3B\n",
              "lOibUZjPDCuJ3IU5ePruDBGouoFWNtlLLqlLAMYTprEH068Zaisl+lPTj2SX6jzBuYJVEzyAAAAA\n",
              "v0Gf2kUVLC//AGcUvOKmyiiim8PGGra2i6FE1FUYhTxUtDAzF7/vOcvAbprWAXZnDBM8/zhz+0AQ\n",
              "c/pukjdSr1bO3G+fGi7QD/pSPh9H+JHqcDD3CnBPewwPR8oZrzKCMm96pW8FgibB/4kifaGwglGr\n",
              "LcRnBohMHRIcypH+xeKY5Ne1aAEDKmfdNOCYq749g/4bFRfszo+eajZo739SfrDpYXFsXcclRoKK\n",
              "UN/5hiErh1XIALuBUmfv/cIfcBFxAAABaQGf+XRCvwCKs8IrQJj6YANE3l47D61OnJUh49x6eR6e\n",
              "IkYzO1z1/NLMVuhb+zDf4XCrwjmd0I2HEzCTUFcayQWKWrKkxJLv64gvqVmVXE+58XSXWSv74miS\n",
              "JiqyqNaI3FiDnQoAZrBipPP83EvGFPJbRgBq38786OGfyDYAI58CnHJCpavnds2cKwuD2E4dU3X/\n",
              "r5vaf1k8fk7o0Fqg3nIK1oW+evThX+CRk4l5ZWnYJjCF2e9Ga80+Q3rJwREFCrpZh5tFr4N7qUUY\n",
              "KSVOhni71u+y5Z1FZU2kmh8ULPo47QIoDEflxSZmhYVGqj/ZFryk3q3VdTlnHRq1FaU4BSJXlMOw\n",
              "8oToiz9oEyW7C9U/b7pvh0os6/ribknJrca6VvBUs2cv2IzeXW/2VgWbdCfZPyr4vTZpOZ5u26OI\n",
              "zVXMBxAO10jmiQ3PMuKY0rvWCWIzITeGme9oeSiMiGa2XqaAbZCJmVudQsAAAAE9AZ/7akK/AIsE\n",
              "kB8Nrh5nNL4j88g01gANi9KJ2a0WhDF/aMijEmzpV0v+aKs7VdySLPx6f7oAjTB2vdAzS6W+pU3K\n",
              "hw/Li8rgkI13ZkrvJvSknl4IW/GBizBlLXEaxc3mMoT3G6ckg8nQlAHPhvLJJjzaE3DgD/1MGZ+U\n",
              "4y4i9bp1a3n2NIP5Wq9zw0oonMv5+YG8XBi4Aa77TjLY9zcTF4+0UAEdTxmdpcag+q2m2EhiOoNa\n",
              "1VaDqL6IN0VYuEVhofx5WHwbosYRdm42VXnVodJWaZ7n6YpFd8b0XQG8xkux235jaMoSSKNeQWIj\n",
              "robBZrnWAUf2eWn6tHNYvNaJOwK7alfpqV79eY2ia8CQBKUBwIuBCtUIl6OjGKYdOK6xJqemthuw\n",
              "YB9pq+DZ8RAR/OAuM1krhcM1rtXtvBkAAAE8QZv/SahBbJlMCFf//jhACfAY80IGADRN5eOveUtU\n",
              "zvbWglm/Cgq+2YN+7gdTALoQVeNnCwUUI13SWEfoy6K/+Dg5H4h01pp3pz/Z4anaxhvyQUMh4ZTi\n",
              "XYz5LPPaGydRWiylh+ejiJTgrH+gNVbzwL4Xbk4wlEWIiYSTpsqj0UUfbTWBSLYVFbL/8ObDUMx8\n",
              "F5ISTATw6xgrSLx6b8Sl2ZlurC95p3YPVPFxeZlbO6KunCQuBta/tKaGClVGXDyyjsGK/cXAOUFk\n",
              "6CwV54ugeh5nxwxzFsi1PyBkPH7MjhaX+/UbJD0DpdzyrK3/ZkZGQaCKG1m/m7aO76QV+iQ/B+BZ\n",
              "2KwjV/4HCkju/Tu/yw19xiepxzKEyg+rwYv6LSB0GKGk/RRzvjGQrOfSrUg1imCiThyp9OGJUUw2\n",
              "YQAAANhBnh1FFSwr/wCGyE9ZLoMeffcrv96sd1EerIf+hQAOZ/R1sAA8Q/Kd35yF0u7aoOsyEfM3\n",
              "HYbmiVCSathFpCtHN1/g/OaMctZBbNZvX3t16vkL216Twuq+yN3PmysUaQwL/QUqmNE6nm2p5Sxi\n",
              "MCdScRwjKeXVi7oVfZ1FYYxHdk1K9kwZ3tyjPSy4M+8+pb8jelUGW0tKtm9UDLfzfAitfEyOsSbS\n",
              "JAQhhIWJS90FB1mV9xyaYndRUptanNNzoPPkXBfJQOJLGWHicwrwMidEGiItSx6sQcAAAADeAZ4+\n",
              "akK/AI7sT7qbl2u/yKpvqDbWPZY2D6hEZRF2Sv9oXJK5qhq3BVBwOfDy6q2tU2o21hoyvBnNNqoo\n",
              "U32NRJljmm+VcmT7kR0ysHiFuF3oLO+JHwd0J7fswJdUCoEPrrBfEtDX0iLsq0OzHOBWhCmjvVy1\n",
              "01Q9M3hCjwhRhZ6my+xKLz1YpgnGMdh6K1g2sC1cfXyujbAsI9SqbDG616UOPRcyCrK9SbW2ygvi\n",
              "oeFk/xk5qJJ6nyQHLPsjvjAOhNyrKa4U+4EkHvNJDu8aFcvUm86YLE25Whp1rK2AAAAEpm1vb3YA\n",
              "AABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAUAAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAA\n",
              "AAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAPQdHJh\n",
              "awAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAUAAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAA\n",
              "AAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAGwAAABIAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAA\n",
              "AAABAAAFAAAABAAAAQAAAAADSG1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAEAAVcQAAAAA\n",
              "AC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAAvNtaW5mAAAAFHZt\n",
              "aGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAKzc3Ri\n",
              "bAAAALNzdHNkAAAAAAAAAAEAAACjYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAGwASAASAAA\n",
              "AEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADFhdmNDAWQA\n",
              "Ff/hABhnZAAVrNlBsJaEAAADAAQAAAMAyDxYtlgBAAZo6+PLIsAAAAAcdXVpZGtoQPJfJE/Fujml\n",
              "G88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAACAAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAEI\n",
              "Y3R0cwAAAAAAAAAfAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEA\n",
              "AAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAA\n",
              "AgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAA\n",
              "AAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQA\n",
              "AAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAcc3RzYwAAAAAAAAABAAAAAQAAACAA\n",
              "AAABAAAAlHN0c3oAAAAAAAAAAAAAACAAAAlCAAADAAAAAVYAAAF8AAABOQAAArcAAAElAAABJAAA\n",
              "ARYAAADfAAABfgAAAOgAAAEgAAABygAAAPMAAADKAAABrAAAAXkAAAE8AAABCQAAAaQAAAFPAAAB\n",
              "CQAAASsAAAEsAAAA9wAAAMMAAAFtAAABQQAAAUAAAADcAAAA4gAAABRzdGNvAAAAAAAAAAEAAAAs\n",
              "AAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAt\n",
              "aWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAACtklEQVR4nO3TMQEAIAzAMMC/52GAnx6Jgj7dM7OAnvM7AHgzJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNC1AVcegTL+uSnUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tWw9n9H0aB5A"
      },
      "source": [
        "## 6. Define Network\n",
        "The network is the same as before. The one difference is that the for-loop iterates through the first dimension of the input:\n",
        "`cur1 = F.max_pool2d(self.conv1(x[step]), 2)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9rOLmqFPjc5k"
      },
      "source": [
        "### Binarized Layer Modules\n",
        "``Binarize`` converts weights to {-1, 1}.\n",
        "Remove `.mul_(2).add_(1)` for {0, 1}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7Z92BOo4j7Ul"
      },
      "source": [
        "import pdb\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Binarize(tensor,quant_mode='det'):\n",
        "    if quant_mode=='det':\n",
        "        return tensor.sign()\n",
        "        # tmp = tensor.clone()\n",
        "        # tmp[tensor>0] = 1\n",
        "        # tmp[tensor==0] = 0\n",
        "        # tmp[tensor<0] = -1\n",
        "        # return tmp\n",
        "    else:\n",
        "        return tensor.add_(1).div_(2).add_(torch.rand(tensor.size()).add(-0.5)).clamp_(0,1).round().mul_(2).add_(-1)\n",
        "\n",
        "\n",
        "class HingeLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HingeLoss,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def hinge_loss(self,input,target):\n",
        "            #import pdb; pdb.set_trace()\n",
        "            output=self.margin-input.mul(target)\n",
        "            output[output.le(0)]=0\n",
        "            return output.mean()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return self.hinge_loss(input,target)\n",
        "\n",
        "class SqrtHingeLossFunction(Function):\n",
        "    def __init__(self):\n",
        "        super(SqrtHingeLossFunction,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        output=self.margin-input.mul(target)\n",
        "        output[output.le(0)]=0\n",
        "        self.save_for_backward(input, target)\n",
        "        loss=output.mul(output).sum(0).sum(1).div(target.numel())\n",
        "        return loss\n",
        "\n",
        "    def backward(self,grad_output):\n",
        "       input, target = self.saved_tensors\n",
        "       output=self.margin-input.mul(target)\n",
        "       output[output.le(0)]=0\n",
        "       import pdb; pdb.set_trace()\n",
        "       grad_output.resize_as_(input).copy_(target).mul_(-2).mul_(output)\n",
        "       grad_output.mul_(output.ne(0).float())\n",
        "       grad_output.div_(input.numel())\n",
        "       return grad_output,grad_output\n",
        "\n",
        "def Quantize(tensor,quant_mode='det',  params=None, numBits=8):\n",
        "    tensor.clamp_(-2**(numBits-1),2**(numBits-1))\n",
        "    if quant_mode=='det':\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().div(2**(numBits-1))\n",
        "    else:\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().add(torch.rand(tensor.size()).add(-0.5)).div(2**(numBits-1))\n",
        "        quant_fixed(tensor, params)\n",
        "    return tensor\n",
        "\n",
        "# import torch.nn._functions as tnnf\n",
        "\n",
        "\n",
        "class BinarizeLinear(nn.Linear):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if input.size(1) != 784:\n",
        "            input.data=Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "        out = nn.functional.linear(input, self.weight)\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1).expand_as(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BinarizeConv2d(nn.Conv2d):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeConv2d, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.size(1) != 3:\n",
        "            input.data = Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "\n",
        "        out = nn.functional.conv2d(input, self.weight, None, self.stride,\n",
        "                                   self.padding, self.dilation, self.groups)\n",
        "\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1, 1, 1).expand_as(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QO_sFhGsj_9Y"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        # self.bn0 = nn.BatchNorm1d(784)\n",
        "        self.fc1 = BinarizeLinear(784, num_hidden)\n",
        "        self.lif1 = Stein_single(alpha=alpha, beta=beta)\n",
        "\n",
        "        self.fc2 = BinarizeLinear(num_hidden, num_outputs)\n",
        "        self.lif2 = Stein_single(alpha=alpha, beta=beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            mask_x = torch.zeros_like(x[step])\n",
        "            index = torch.argmax(x[step], dim=-1)\n",
        "            mask_x[torch.arange(x[step].size()[0]), index] = 1\n",
        "            x_in = (x[step] * mask_x)\n",
        "            cur1 = self.fc1(x[step])\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nzpf57Q1aB5B"
      },
      "source": [
        "## 7. Training\n",
        "We make a slight modification to our print-out functions to handle the new first dimension of the input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w1saOFIFaB5B"
      },
      "source": [
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    output, _ = net(data.view(num_steps, batch_size, -1))\n",
        "    # output, _ = net(data.view(num_steps, batch_size, 1, 28, 28))\n",
        "    _, idx = output.sum(dim=0).max(1)\n",
        "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
        "\n",
        "    if train:\n",
        "        print(f\"Train Set Accuracy: {acc}\")\n",
        "    else:\n",
        "        print(f\"Test Set Accuracy: {acc}\")\n",
        "\n",
        "def train_printer():\n",
        "    print(f\"Epoch {epoch}, Minibatch {minibatch_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]}\")\n",
        "    print_batch_accuracy(spike_data, spike_targets, train=True)\n",
        "    print_batch_accuracy(test_spike_data, test_spike_targets, train=False)\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "V9qnIq0MaB5B"
      },
      "source": [
        "### 7.1 Optimizer & Loss\n",
        "We'll keep our optimizer and loss the exact same as the static MNIST case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KeWZQlzEaB5B"
      },
      "source": [
        "lr = 5e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VCHfUz7waB5C"
      },
      "source": [
        "### 7.2 Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "H_P1ffX-kIvR"
      },
      "source": [
        "High precision BPTT training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noSeE-t4kN33",
        "outputId": "b55519ab-438e-458a-a0ec-3e9c2614954f"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    new_lr = lr * (0.85 ** epoch)\n",
        "    # lr = lr\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_lr\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(10):\n",
        "\n",
        "    minibatch_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in train_batch:\n",
        "        \n",
        "\n",
        "        # Spike generator\n",
        "        # data_it_sum = torch.sum(data_it, dim=(-2, -1)).squeeze()\n",
        "        # data_it_tmp = torch.movedim(data_it, 0, -1)\n",
        "        # # print(data_it_sum.size())\n",
        "        # # print(data_it_tmp.size())\n",
        "        # data_it_tmp = data_it_tmp / data_it_sum\n",
        "        # data_it = torch.movedim(data_it_tmp, -1, 0)\n",
        "\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        spike_data, spike_targets = spikegen.rate(data_it, targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                  gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "        \n",
        "\n",
        "        # Forward pass\n",
        "        output, mem_rec = net(spike_data.view(num_steps, batch_size, -1))\n",
        "        # output, mem_rec = net(spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "        \n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # BNN OPTimization\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.data.copy_(p.org)\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.org.copy_(p.data.clamp_(-1,1))\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "\n",
        "        # testdata_it_sum = torch.sum(testdata_it, dim=(-2, -1)).squeeze()\n",
        "        # testdata_it_tmp = torch.movedim(testdata_it, 0, -1)\n",
        "        # # print(data_it_sum.size())\n",
        "        # # print(data_it_tmp.size())\n",
        "        # testdata_it_tmp = testdata_it_tmp / testdata_it_sum\n",
        "        # testdata_it = torch.movedim(testdata_it_tmp, -1, 0)\n",
        "\n",
        "        \n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set spike conversion\n",
        "        test_spike_data, test_spike_targets = spikegen.rate(testdata_it, testtargets_it, num_outputs=num_outputs,\n",
        "                                                            num_steps=num_steps, gain=1, offset=0, convert_targets=False,\n",
        "                                                            temporal_targets=False)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "          train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      for data in test_loader:\n",
        "        images, labels = data\n",
        "        \n",
        "\n",
        "        # images_sum = torch.sum(images, dim=(-2, -1)).squeeze()\n",
        "        # images_tmp = torch.movedim(images, 0, -1)\n",
        "        # # print(data_it_sum.size())\n",
        "        # # print(data_it_tmp.size())\n",
        "        # images_tmp = images_tmp / images_sum\n",
        "        # images = torch.movedim(images_tmp, -1, 0)\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # If current batch matches batch_size, just do the usual thing\n",
        "        if images.size()[0] == batch_size:\n",
        "          \n",
        "          spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                                gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "          outputs, _ = net(spike_test.view(num_steps, batch_size, -1))\n",
        "          # outputs, _ = net(spike_test.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "        # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "        # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "        else:\n",
        "          temp_bs = batch_size\n",
        "          batch_size = images.size()[0]\n",
        "          spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                                gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "          outputs, _ = net(spike_test.view(num_steps, images.size()[0], -1))\n",
        "          # outputs, _ = net(spike_test.view(num_steps, images.size()[0], 1, 28, 28))\n",
        "          batch_size = temp_bs\n",
        "\n",
        "        _, predicted = outputs.sum(dim=0).max(1)\n",
        "        total += spike_targets.size(0)\n",
        "        correct += (predicted == spike_targets).sum().item()\n",
        "\n",
        "    print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "    print(f\"Test Set Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "    \n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Minibatch 0\n",
            "Train Set Loss: 87.87235260009766\n",
            "Test Set Loss: 80.05778503417969\n",
            "Train Set Accuracy: 0.3125\n",
            "Test Set Accuracy: 0.2109375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 50\n",
            "Train Set Loss: 40.13042449951172\n",
            "Test Set Loss: 37.71418380737305\n",
            "Train Set Accuracy: 0.75\n",
            "Test Set Accuracy: 0.7734375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 100\n",
            "Train Set Loss: 32.834075927734375\n",
            "Test Set Loss: 29.725584030151367\n",
            "Train Set Accuracy: 0.8203125\n",
            "Test Set Accuracy: 0.8828125\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 150\n",
            "Train Set Loss: 31.436878204345703\n",
            "Test Set Loss: 29.882272720336914\n",
            "Train Set Accuracy: 0.8515625\n",
            "Test Set Accuracy: 0.84375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 200\n",
            "Train Set Loss: 25.71311378479004\n",
            "Test Set Loss: 29.638935089111328\n",
            "Train Set Accuracy: 0.9140625\n",
            "Test Set Accuracy: 0.8515625\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 250\n",
            "Train Set Loss: 27.857219696044922\n",
            "Test Set Loss: 25.13030242919922\n",
            "Train Set Accuracy: 0.890625\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 300\n",
            "Train Set Loss: 24.12862777709961\n",
            "Test Set Loss: 29.664941787719727\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 0.828125\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 350\n",
            "Train Set Loss: 27.62216567993164\n",
            "Test Set Loss: 27.800657272338867\n",
            "Train Set Accuracy: 0.859375\n",
            "Test Set Accuracy: 0.875\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 400\n",
            "Train Set Loss: 29.55301284790039\n",
            "Test Set Loss: 26.308034896850586\n",
            "Train Set Accuracy: 0.859375\n",
            "Test Set Accuracy: 0.859375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 450\n",
            "Train Set Loss: 23.664518356323242\n",
            "Test Set Loss: 24.098102569580078\n",
            "Train Set Accuracy: 0.9140625\n",
            "Test Set Accuracy: 0.921875\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9071/10000\n",
            "Test Set Accuracy: 90.71%\n",
            "Epoch 1, Minibatch 32\n",
            "Train Set Loss: 21.67499542236328\n",
            "Test Set Loss: 25.804643630981445\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.890625\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 82\n",
            "Train Set Loss: 23.531644821166992\n",
            "Test Set Loss: 23.429523468017578\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.9296875\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 132\n",
            "Train Set Loss: 22.9016170501709\n",
            "Test Set Loss: 24.341856002807617\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.90625\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 182\n",
            "Train Set Loss: 21.75303840637207\n",
            "Test Set Loss: 21.452392578125\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 232\n",
            "Train Set Loss: 23.190900802612305\n",
            "Test Set Loss: 23.702192306518555\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.9140625\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 282\n",
            "Train Set Loss: 22.02513313293457\n",
            "Test Set Loss: 23.25756072998047\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9296875\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 332\n",
            "Train Set Loss: 21.77518653869629\n",
            "Test Set Loss: 21.763935089111328\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9296875\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 382\n",
            "Train Set Loss: 23.25959587097168\n",
            "Test Set Loss: 20.658458709716797\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 432\n",
            "Train Set Loss: 25.056406021118164\n",
            "Test Set Loss: 23.44762420654297\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.9140625\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9288/10000\n",
            "Test Set Accuracy: 92.88%\n",
            "Epoch 2, Minibatch 14\n",
            "Train Set Loss: 23.01889419555664\n",
            "Test Set Loss: 21.917692184448242\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 64\n",
            "Train Set Loss: 21.571754455566406\n",
            "Test Set Loss: 22.98581314086914\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 0.9140625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 114\n",
            "Train Set Loss: 24.78892707824707\n",
            "Test Set Loss: 20.587230682373047\n",
            "Train Set Accuracy: 0.90625\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 164\n",
            "Train Set Loss: 21.894145965576172\n",
            "Test Set Loss: 19.643014907836914\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 214\n",
            "Train Set Loss: 23.906723022460938\n",
            "Test Set Loss: 19.708988189697266\n",
            "Train Set Accuracy: 0.9140625\n",
            "Test Set Accuracy: 0.96875\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 264\n",
            "Train Set Loss: 21.339305877685547\n",
            "Test Set Loss: 23.148221969604492\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.90625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 314\n",
            "Train Set Loss: 20.349750518798828\n",
            "Test Set Loss: 21.64222526550293\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.9296875\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 364\n",
            "Train Set Loss: 21.108448028564453\n",
            "Test Set Loss: 21.033538818359375\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 414\n",
            "Train Set Loss: 20.33686637878418\n",
            "Test Set Loss: 21.957035064697266\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.921875\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 464\n",
            "Train Set Loss: 20.581623077392578\n",
            "Test Set Loss: 20.68049430847168\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9395/10000\n",
            "Test Set Accuracy: 93.95%\n",
            "Epoch 3, Minibatch 46\n",
            "Train Set Loss: 21.515329360961914\n",
            "Test Set Loss: 19.69877052307129\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 96\n",
            "Train Set Loss: 20.922378540039062\n",
            "Test Set Loss: 20.613258361816406\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.96875\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 146\n",
            "Train Set Loss: 19.633922576904297\n",
            "Test Set Loss: 20.703927993774414\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 196\n",
            "Train Set Loss: 21.680944442749023\n",
            "Test Set Loss: 19.58163833618164\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 0.96875\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 246\n",
            "Train Set Loss: 20.26312828063965\n",
            "Test Set Loss: 19.120758056640625\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.96875\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 296\n",
            "Train Set Loss: 20.493093490600586\n",
            "Test Set Loss: 19.68109703063965\n",
            "Train Set Accuracy: 0.9765625\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 346\n",
            "Train Set Loss: 21.324769973754883\n",
            "Test Set Loss: 20.761838912963867\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 396\n",
            "Train Set Loss: 21.543888092041016\n",
            "Test Set Loss: 21.6643009185791\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 446\n",
            "Train Set Loss: 19.209949493408203\n",
            "Test Set Loss: 20.911767959594727\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9486/10000\n",
            "Test Set Accuracy: 94.86%\n",
            "Epoch 4, Minibatch 28\n",
            "Train Set Loss: 21.594133377075195\n",
            "Test Set Loss: 17.708621978759766\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.9765625\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 78\n",
            "Train Set Loss: 19.017093658447266\n",
            "Test Set Loss: 19.93294334411621\n",
            "Train Set Accuracy: 0.9765625\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 128\n",
            "Train Set Loss: 20.24488067626953\n",
            "Test Set Loss: 20.7841796875\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9296875\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 178\n",
            "Train Set Loss: 19.067323684692383\n",
            "Test Set Loss: 20.014989852905273\n",
            "Train Set Accuracy: 0.9765625\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 228\n",
            "Train Set Loss: 20.564119338989258\n",
            "Test Set Loss: 21.270509719848633\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.921875\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 278\n",
            "Train Set Loss: 20.012208938598633\n",
            "Test Set Loss: 22.217693328857422\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.921875\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 328\n",
            "Train Set Loss: 22.076141357421875\n",
            "Test Set Loss: 20.029529571533203\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 378\n",
            "Train Set Loss: 20.053585052490234\n",
            "Test Set Loss: 21.270978927612305\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 4, Minibatch 428\n",
            "Train Set Loss: 21.23887062072754\n",
            "Test Set Loss: 19.59282684326172\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9519/10000\n",
            "Test Set Accuracy: 95.19%\n",
            "Epoch 5, Minibatch 10\n",
            "Train Set Loss: 20.41116714477539\n",
            "Test Set Loss: 22.69766616821289\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.90625\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 60\n",
            "Train Set Loss: 21.479883193969727\n",
            "Test Set Loss: 21.360977172851562\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 110\n",
            "Train Set Loss: 20.994844436645508\n",
            "Test Set Loss: 19.61079978942871\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 160\n",
            "Train Set Loss: 20.453350067138672\n",
            "Test Set Loss: 21.222192764282227\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 210\n",
            "Train Set Loss: 19.92247200012207\n",
            "Test Set Loss: 19.75539779663086\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 260\n",
            "Train Set Loss: 21.64806365966797\n",
            "Test Set Loss: 20.965913772583008\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 310\n",
            "Train Set Loss: 22.03252410888672\n",
            "Test Set Loss: 17.006023406982422\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 360\n",
            "Train Set Loss: 18.333681106567383\n",
            "Test Set Loss: 20.69231414794922\n",
            "Train Set Accuracy: 0.9765625\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 410\n",
            "Train Set Loss: 19.142433166503906\n",
            "Test Set Loss: 20.5745849609375\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 5, Minibatch 460\n",
            "Train Set Loss: 17.458765029907227\n",
            "Test Set Loss: 20.25564956665039\n",
            "Train Set Accuracy: 0.9921875\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9540/10000\n",
            "Test Set Accuracy: 95.4%\n",
            "Epoch 6, Minibatch 42\n",
            "Train Set Loss: 17.854656219482422\n",
            "Test Set Loss: 17.99918556213379\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.984375\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 92\n",
            "Train Set Loss: 19.03900909423828\n",
            "Test Set Loss: 20.22974967956543\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 142\n",
            "Train Set Loss: 20.521547317504883\n",
            "Test Set Loss: 18.541858673095703\n",
            "Train Set Accuracy: 0.9765625\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 192\n",
            "Train Set Loss: 18.616313934326172\n",
            "Test Set Loss: 20.613115310668945\n",
            "Train Set Accuracy: 0.984375\n",
            "Test Set Accuracy: 0.9765625\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 242\n",
            "Train Set Loss: 17.94660186767578\n",
            "Test Set Loss: 20.213151931762695\n",
            "Train Set Accuracy: 0.984375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 292\n",
            "Train Set Loss: 20.027454376220703\n",
            "Test Set Loss: 21.383697509765625\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 342\n",
            "Train Set Loss: 21.19048309326172\n",
            "Test Set Loss: 19.135845184326172\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.9765625\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 392\n",
            "Train Set Loss: 19.30613136291504\n",
            "Test Set Loss: 19.66848373413086\n",
            "Train Set Accuracy: 0.984375\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 6, Minibatch 442\n",
            "Train Set Loss: 20.0863094329834\n",
            "Test Set Loss: 22.110631942749023\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9515/10000\n",
            "Test Set Accuracy: 95.15%\n",
            "Epoch 7, Minibatch 24\n",
            "Train Set Loss: 21.389230728149414\n",
            "Test Set Loss: 20.568326950073242\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.96875\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 74\n",
            "Train Set Loss: 19.958240509033203\n",
            "Test Set Loss: 21.98925018310547\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 124\n",
            "Train Set Loss: 21.13376235961914\n",
            "Test Set Loss: 20.488523483276367\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 174\n",
            "Train Set Loss: 20.446992874145508\n",
            "Test Set Loss: 17.635581970214844\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.9921875\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 224\n",
            "Train Set Loss: 19.48095703125\n",
            "Test Set Loss: 20.70726776123047\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 274\n",
            "Train Set Loss: 20.459381103515625\n",
            "Test Set Loss: 20.185714721679688\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 324\n",
            "Train Set Loss: 20.303558349609375\n",
            "Test Set Loss: 17.828699111938477\n",
            "Train Set Accuracy: 0.9765625\n",
            "Test Set Accuracy: 0.9921875\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 374\n",
            "Train Set Loss: 21.973588943481445\n",
            "Test Set Loss: 19.30046844482422\n",
            "Train Set Accuracy: 0.921875\n",
            "Test Set Accuracy: 0.9765625\n",
            "\n",
            "\n",
            "Epoch 7, Minibatch 424\n",
            "Train Set Loss: 21.08736801147461\n",
            "Test Set Loss: 23.16275405883789\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9296875\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9522/10000\n",
            "Test Set Accuracy: 95.22%\n",
            "Epoch 8, Minibatch 6\n",
            "Train Set Loss: 19.4316463470459\n",
            "Test Set Loss: 18.16802215576172\n",
            "Train Set Accuracy: 0.96875\n",
            "Test Set Accuracy: 0.9765625\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 56\n",
            "Train Set Loss: 19.99535369873047\n",
            "Test Set Loss: 20.550830841064453\n",
            "Train Set Accuracy: 0.9921875\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 106\n",
            "Train Set Loss: 19.162353515625\n",
            "Test Set Loss: 20.131200790405273\n",
            "Train Set Accuracy: 0.984375\n",
            "Test Set Accuracy: 0.9765625\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 156\n",
            "Train Set Loss: 19.351699829101562\n",
            "Test Set Loss: 19.560461044311523\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.96875\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 206\n",
            "Train Set Loss: 21.812816619873047\n",
            "Test Set Loss: 21.236812591552734\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.9609375\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 256\n",
            "Train Set Loss: 21.0692138671875\n",
            "Test Set Loss: 19.542583465576172\n",
            "Train Set Accuracy: 0.9375\n",
            "Test Set Accuracy: 0.984375\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 306\n",
            "Train Set Loss: 20.23246955871582\n",
            "Test Set Loss: 20.173452377319336\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 356\n",
            "Train Set Loss: 20.549846649169922\n",
            "Test Set Loss: 21.854751586914062\n",
            "Train Set Accuracy: 0.984375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 406\n",
            "Train Set Loss: 21.102054595947266\n",
            "Test Set Loss: 21.93042755126953\n",
            "Train Set Accuracy: 0.9453125\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 8, Minibatch 456\n",
            "Train Set Loss: 20.30781364440918\n",
            "Test Set Loss: 22.778884887695312\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.9375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9509/10000\n",
            "Test Set Accuracy: 95.09%\n",
            "Epoch 9, Minibatch 38\n",
            "Train Set Loss: 21.6772518157959\n",
            "Test Set Loss: 20.657384872436523\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.96875\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 88\n",
            "Train Set Loss: 18.11123275756836\n",
            "Test Set Loss: 24.157468795776367\n",
            "Train Set Accuracy: 0.9921875\n",
            "Test Set Accuracy: 0.8984375\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 138\n",
            "Train Set Loss: 19.896591186523438\n",
            "Test Set Loss: 20.32565689086914\n",
            "Train Set Accuracy: 0.984375\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 188\n",
            "Train Set Loss: 22.80723762512207\n",
            "Test Set Loss: 21.464933395385742\n",
            "Train Set Accuracy: 0.9296875\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 238\n",
            "Train Set Loss: 21.49138832092285\n",
            "Test Set Loss: 22.238811492919922\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.9140625\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 288\n",
            "Train Set Loss: 18.498289108276367\n",
            "Test Set Loss: 22.260780334472656\n",
            "Train Set Accuracy: 0.9921875\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 338\n",
            "Train Set Loss: 20.92524528503418\n",
            "Test Set Loss: 22.265335083007812\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.90625\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 388\n",
            "Train Set Loss: 19.716922760009766\n",
            "Test Set Loss: 22.623533248901367\n",
            "Train Set Accuracy: 0.9609375\n",
            "Test Set Accuracy: 0.9453125\n",
            "\n",
            "\n",
            "Epoch 9, Minibatch 438\n",
            "Train Set Loss: 21.308229446411133\n",
            "Test Set Loss: 21.754745483398438\n",
            "Train Set Accuracy: 0.953125\n",
            "Test Set Accuracy: 0.953125\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 9512/10000\n",
            "Test Set Accuracy: 95.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nVldb0Q9aB5C"
      },
      "source": [
        "## 8. Spiking MNIST Results\n",
        "### 8.1 Plot Training/Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK2U7IRAJqs4"
      },
      "source": [
        "# tmp = torch.arange(20).view(2,2,5)\n",
        "# print(tmp)\n",
        "# print(torch.sum(tmp, dim=(0,1)))\n",
        "# print(tmp / torch.sum(tmp, dim=(0,1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XopHe17ZaB5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "ec5a3551-f390-4706-b38e-aaaa314791c7"
      },
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "plt.plot(loss_hist)\n",
        "plt.plot(test_loss_hist)\n",
        "plt.legend([\"Test Loss\", \"Train Loss\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lgu-tzsfaB5C"
      },
      "source": [
        "### 8.2 Test Set Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nyIVun6laB5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df8fd86-ca9e-40a0-ff63-de2b6c4f5491"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  for data in test_loader:\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # If current batch matches batch_size, just do the usual thing\n",
        "    if images.size()[0] == batch_size:\n",
        "      spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                            gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "      outputs, _ = net(spike_test.view(num_steps, batch_size, -1))\n",
        "      # outputs, _ = net(spike_test.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "    # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "    # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "    else:\n",
        "      temp_bs = batch_size\n",
        "      batch_size = images.size()[0]\n",
        "      spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                            gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "      outputs, _ = net(spike_test.view(num_steps, images.size()[0], -1))\n",
        "      # outputs, _ = net(spike_test.view(num_steps, images.size()[0], 1, 28, 28))\n",
        "      batch_size = temp_bs\n",
        "\n",
        "    _, predicted = outputs.sum(dim=0).max(1)\n",
        "    total += spike_targets.size(0)\n",
        "    correct += (predicted == spike_targets).sum().item()\n",
        "\n",
        "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "print(f\"Test Set Accuracy: {100 * correct / total}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total correctly classified test set images: 9524/10000\n",
            "Test Set Accuracy: 95.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fuzanqrCaB5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "49fec2d5-6aaf-4bc2-9f36-1dffff939b32"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(1):\n",
        "    minibatch_counter = 0\n",
        "    data = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in data:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        # Spike generator\n",
        "        spike_data, spike_targets = spikegen.rate(data_it, targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                  gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "        # Forward pass\n",
        "        output, mem_rec = net(spike_data.view(num_steps, batch_size, -1))\n",
        "        # output, mem_rec = net(spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "\n",
        "        # Gradient Calculation\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward(retain_graph=True)\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "\n",
        "        # Weight Update\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store Loss history\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set spike conversion\n",
        "        test_spike_data, test_spike_targets = spikegen.rate(testdata_it, testtargets_it, num_outputs=num_outputs,\n",
        "                                                            num_steps=num_steps, gain=1, offset=0, convert_targets=False,\n",
        "                                                            temporal_targets=False)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, test_spike_targets)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "            train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Minibatch 0\n",
            "Train Set Loss: 17.53070068359375\n",
            "Test Set Loss: 19.592514038085938\n",
            "Train Set Accuracy: 0.8359375\n",
            "Test Set Accuracy: 0.796875\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-00bc68d644bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# output, mem_rec = net(spike_data.view(num_steps, batch_size, 1, 28, 28))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_softmax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_rec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-9bfae6026904>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mspk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcur2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mspk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mspk2_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/snntorch/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mspk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0msyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/snntorch/__init__.py\u001b[0m in \u001b[0;36mfire\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mspk_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmem_shift\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mreset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspk_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspk_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zIpvq5jdaB5B"
      },
      "source": [
        "# spike_fn = FSS.apply\n",
        "# snn.neuron.slope = 50\n",
        "spike_grad = snn.FastSigmoidSurrogate.apply\n",
        "snn.slope = 50\n",
        "\n",
        "def Binarize(tensor):\n",
        "    tensor[tensor > 0] = 1\n",
        "    tensor[tensor<=0] = 0\n",
        "    return tensor\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#     # initialize layers\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.fc2 = nn.Linear(64*5*5, 10, bias= False)\n",
        "#         self.lif3 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize LIF state variables and spike output tensors\n",
        "#         spk1, syn1, mem1 = self.lif1.init_stein(batch_size, 12, 13, 13)\n",
        "#         spk2, syn2, mem2 = self.lif1.init_stein(batch_size, 64, 5, 5)\n",
        "#         spk3, syn3, mem3 = self.lif2.init_stein(batch_size, 10)\n",
        "\n",
        "#         spk3_rec = []\n",
        "#         mem3_rec = []\n",
        "\n",
        "#         for step in range(num_steps):\n",
        "#             conv1_bin_weight = self.conv1.weight.data.clone()\n",
        "#             self.conv1.weight.data = Binarize(conv1_bin_weight)\n",
        "            \n",
        "#             cur1 = F.max_pool2d(self.conv1(x[step]), 2)\n",
        "#             # cur1 = F.max_pool2d(F.conv2d(x, self.conv1.weight, bias=None, stride=1,\n",
        "#             #                        padding=1), 2)\n",
        "            \n",
        "#             spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "#             conv2_bin_weight = self.conv2.weight.data.clone()\n",
        "#             self.conv2.weight.data = Binarize(conv2_bin_weight)\n",
        "\n",
        "#             cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "#             # cur2 = F.max_pool2d(F.conv2d(spk1, self.conv2.weight, bias=None, stride=1,\n",
        "#             #                        padding=1), 2)\n",
        "            \n",
        "#             spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "#             fc_bin_weight = self.fc2.weight.data.clone()\n",
        "#             self.fc2.weight.data = Binarize(fc_bin_weight)\n",
        "\n",
        "#             cur3 = self.fc2(spk2.view(batch_size, -1))\n",
        "#             # cur3 = F.linear(spk2.view(batch_size, -1), self.fc2.weight)\n",
        "#             spk3, syn3, mem3 = self.lif3(cur3, syn3, mem3)\n",
        "\n",
        "#             spk3_rec.append(spk3)\n",
        "#             mem3_rec.append(mem3)\n",
        "\n",
        "#         return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
        "\n",
        "# net = Net().to(device)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden, bias=False)\n",
        "        self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs, bias=False)\n",
        "        self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            fc1_bin_weight = self.fc1.weight.data.clone()\n",
        "            self.fc1.weight.data = Binarize(fc1_bin_weight)\n",
        "            cur1 = self.fc1(x[step])\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "            fc2_bin_weight = self.fc2.weight.data.clone()\n",
        "            self.fc2.weight.data = Binarize(fc2_bin_weight)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "            # print(spk2.shape)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # initialize layers\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "#         self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=5, stride=1, padding=1)\n",
        "#         self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.fc2 = nn.Linear(64*5*5, 10)\n",
        "#         self.lif3 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "#         # self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=0)\n",
        "#         # self.lif1 = LIF(spike_fn=spike_fn, alpha=alpha, beta=beta)\n",
        "#         # self.fc1 = nn.Linear(26*26*3, 10)\n",
        "#         # self.lif2 = LIF(spike_fn=spike_fn, alpha=alpha, beta=beta)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize LIF state variables and spike output tensors\n",
        "#         spk1, syn1, mem1 = self.lif1.init_stein(batch_size, 12, 13, 13)\n",
        "#         spk2, syn2, mem2 = self.lif2.init_stein(batch_size, 64, 5, 5)\n",
        "#         spk3, syn3, mem3 = self.lif3.init_stein(batch_size, 10)\n",
        "\n",
        "#         spk3_rec = []\n",
        "#         mem3_rec = []\n",
        "\n",
        "#         for step in range(num_steps):\n",
        "#             cur1 = F.max_pool2d(self.conv1(x[step]), 2) # add max-pooling to membrane or spikes?\n",
        "#             spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "#             cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "#             spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "#             cur3 = self.fc2(spk2.view(batch_size, -1))\n",
        "#             spk3, syn3, mem3 = self.lif3(cur3, syn3, mem3)\n",
        "\n",
        "#             spk3_rec.append(spk3)\n",
        "#             mem3_rec.append(mem3)\n",
        "\n",
        "#         return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
        "\n",
        "# net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WcBkni9VaB5D"
      },
      "source": [
        "Professor Lu has kidnapped my daughter and won't return her until I hit 99.99% accuracy, please help\n",
        "-JE"
      ]
    }
  ]
}