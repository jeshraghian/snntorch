{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of quantAwareTrain.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9QXsrr6Mp5e_",
        "1EWDw3bip8Ie",
        "vFM8UV9CreIX",
        "xXkTAJ9ws1Y6",
        "OgkWg605tE1y",
        "OBt0WDzyujnk",
        "xC96eesMqYo-",
        "mszPTrYOluym",
        "VTHK-wAWV57B"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBNKFLJIobYt"
      },
      "source": [
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"400\">\n",
        "\n",
        "# snnTorch - Spike Generation and Visualization with `spikegen` and `spikeplot`\n",
        "## Tutorial 1\n",
        "### By Jason K. Eshraghian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lnF_PEo5obYv"
      },
      "source": [
        "# Introduction\n",
        "In this tutorial, you will learn how to use snnTorch to:\n",
        "* convert datasets into spiking datasets using various encoding methods, \n",
        "* how to visualise them, \n",
        "* and how to generate random spike trains.\n",
        "\n",
        "If running in Google Colab:\n",
        "* You may connect to GPU by checking `Runtime` > `Change runtime type` > `Hardware accelerator: GPU`\n",
        "* Next, install the latest PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jxLoYgkhobYw"
      },
      "source": [
        "!pip install snntorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6E7VH5kbTmA"
      },
      "source": [
        "## 1. Setting up the MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Suffg8_ZobYw"
      },
      "source": [
        "### 1.1. Import packages and setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cR9okh0jobYx"
      },
      "source": [
        "import snntorch as snn\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z5hlhbUobYx"
      },
      "source": [
        "Let's define a few variables.\n",
        "\n",
        "`data_path` will be used as the target directory for downloading the training set.\n",
        "\n",
        "`valid_split` will be used to assign data from the training set to the validation set.\n",
        "*E.g., for a split of 0.1, the validation set will be made up of 10% of the train set.*\n",
        "\n",
        "`subset` is used to partition the training and test sets down by the given factor.\n",
        "*E.g., for a subset of 10, a training set of 60,000 will be reduced to 6,000.*\n",
        "\n",
        "`num_steps` is the number of time steps to simulate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e4LPD0WCobYx"
      },
      "source": [
        "# Training Parameters\n",
        "batch_size=128\n",
        "data_path='/data/mnist'\n",
        "val_split = 0.1\n",
        "subset = 10\n",
        "num_outputs = 10\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 100\n",
        "\n",
        "# Torch Variables\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5X2a5a9obYy"
      },
      "source": [
        "### 1.2 Download Dataset\n",
        "\n",
        "MNIST does not have a specified validation set by default. So we can make a copy of the training set in `mnist_val`.\n",
        "We won't use `mnist_val` or `mnist_test` here - they're only to demonstrate creating a train-validation split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OlbY8Rm9obYy"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28,28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_val = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "s8rZwawgobYy"
      },
      "source": [
        "`snntorch.utils` contains a few useful functions for modifying datasets.\n",
        "A train-validation split can be created by calling `valid_split`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z2AE1-TxobYy"
      },
      "source": [
        "from snntorch import utils\n",
        "\n",
        "mnist_train, mnist_val = utils.valid_split(mnist_train, mnist_val, val_split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "T5wXl2bVobYz"
      },
      "source": [
        "Until we actually start doing some training, we won't need large datasets.\n",
        "So let's make our life simpler by reducing the size of the MNIST dataset.\n",
        "We can apply `data_subset` to reduce the dataset by the factor given in the argument `subset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5FPsPU46obYz"
      },
      "source": [
        "mnist_train = utils.data_subset(mnist_train, subset)\n",
        "mnist_val = utils.data_subset(mnist_val, subset)\n",
        "mnist_test = utils.data_subset(mnist_test, subset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BSjMhKPdobYz"
      },
      "source": [
        "To verify, we can take a look at the length of each of our datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nfMSCZGxobYz"
      },
      "source": [
        "print(f\"The size of mnist_train is {len(mnist_train)}\")\n",
        "print(f\"The size of mnist_val is {len(mnist_val)}\")\n",
        "print(f\"The size of mnist_test is {len(mnist_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9CedMagsobY0"
      },
      "source": [
        "### 1.3 Create DataLoaders\n",
        "The Dataset objects we created above load training/validation/test data into memory, and the DataLoader will fetch data from this dataset and serve it up in batches. \n",
        "\n",
        "DataLoaders in PyTorch are a handy interface for passing data into a network. They return an iterator divided up into mini-batches of size ``batch_size``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TrJLlWj2obY0"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(mnist_val, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mwSdczxKobY0"
      },
      "source": [
        "## 2. Spike Encoding\n",
        "Spiking Neural Networks (SNNs) are made to exploit time-varying data. And yet, MNIST is not a time-varying dataset. \n",
        "This means that we have one of two options for passing input data into an SNN:\n",
        "\n",
        "1. Directly feed the same static input features $x_i^{m}$ at each time step, where $x^{i}$ takes on an analog value $x^{i} \\in$  [0, 1].\n",
        " This is like converting MNIST into a static, unchanging video.\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_1_static.png?raw=true' width=\"800\">\n",
        "</center>\n",
        "\n",
        "2. Convert the input into a spike train of sequence length `num_steps`, where $x^{i}$ takes on a discrete value $x^{i}\n",
        " \\in$ {0, 1}.\n",
        "In this case, MNIST would become a time-varying sequence of spikes that are related to the original image.\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_2_spikeinput.png?raw=true' width=\"800\">\n",
        "</center>\n",
        "\n",
        "The first method is quite straightforward, so let's consider (2) in more detail.\n",
        "\n",
        "The module `snntorch.spikegen` contains a series of functions that simplify the conversion of data into spikes. There are currently three options available for spike generation in `snntorch`:\n",
        "\n",
        "1. Rate coding: [`spikegen.rate`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.rate)\n",
        "2. Latency coding: [`spikegen.latency`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.latency)\n",
        "3. Delta modulation: [`spikegen.delta`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.delta)\n",
        "\n",
        "*Rate coding* uses input features to determine spiking **frequency**. *Latency coding* uses input features to determine spike **timing**. *Delta modulation* uses the temporal **change** of input features to generate spikes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D5HSoY4bQDm"
      },
      "source": [
        "\r\n",
        "### 2.1 Rate coding of MNIST\r\n",
        "\r\n",
        "Each input feature is used as the probability an event occurs, sampled from a binomial distribution. Formally, $X$~$B(n=1, p=x^{i})$ where the\r\n",
        "**expected value** $\\mathbb E[X]=x^{i}$ is simply the probability that a spike is generated at any given time step.\r\n",
        "\r\n",
        "For an MNIST image, this probability corresponds to the pixel value. A white pixel corresponds to a 100% probability of spiking, and a black pixel will never generate a spike.\r\n",
        "\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_3_spikeconv.png?raw=true' width=\"800\">\r\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nz70JGXqobY1"
      },
      "source": [
        "from snntorch import spikegen\n",
        "\n",
        "# Iterate through minibatches\n",
        "data = iter(train_loader)\n",
        "data_it, targets_it = next(data)\n",
        "data_it = data_it.to(device)\n",
        "targets_it = targets_it.to(device)\n",
        "\n",
        "# Spiking Data\n",
        "spike_data, spike_targets = spikegen.rate(data_it, targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                          gain=1, offset=0, one_hot=False, time_varying_targets=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "q0hATEwKobY1"
      },
      "source": [
        "As you can see, `spikegen.rate` takes a few arguments that can modify spiking probability:\n",
        "\n",
        "* `gain` multiplies the input by the given factor, and\n",
        "* `offset` applies a level-shift to the input.\n",
        "\n",
        "If the result falls outside of [0,1], then it will automatically be clipped such that the feature represents a probability.\n",
        "\n",
        "Note: there are also options to convert targets to one hot encodings using `one_hot`, and to extend the encodings along the time-axis using `time_varying_targets`.\n",
        "Both are set to `False`, so `targets_it` is simply passed directly to `spike_targets` without any modification. We may also remove `targets_it` as an argument, and only return `spike_data`. Fore more detail on converting targets to spikes, please [refer to the documentation of `snntorch.spikegen` here](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.targets_to_spikes).\n",
        "\n",
        "The structure of the input data is ``[num_steps x batch_size x input dimensions]``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ebdP5kFKobY2"
      },
      "source": [
        "print(spike_data.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "oVFuIXxMobY2"
      },
      "source": [
        "### 2.2 Visualization\n",
        "#### 2.2.1 Animation\n",
        "snnTorch contains a module [`snntorch.spikeplot`](https://snntorch.readthedocs.io/en/latest/snntorch.spikeplot.html) that can simplify the process of visualizing, plotting, and animating spiking neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TYFlc4_ZK-u"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import snntorch.spikeplot as splt\r\n",
        "from IPython.display import HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fwWROIkdobY3"
      },
      "source": [
        "To plot one sample of data, we have to index into the batch (B) dimension of `spike_data`, ``[T x B x 1 x 28 x 28]``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZZxTqqOlobY3"
      },
      "source": [
        "spike_data_sample = spike_data[:, 0, 0]\n",
        "print(spike_data_sample.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJJyPUiuQ61x"
      },
      "source": [
        "`spikeplot.animator` enables super simple animation of 2-D data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4QVyvj9PobY3"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample, fig, ax)\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ko8KJBCNobY4"
      },
      "source": [
        "# If you're feeling sentimental, you can save the animation: .gif, .mp4 etc.\n",
        "anim.save(\"spike_mnist_test.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gu1_f0XZobY4"
      },
      "source": [
        "The associated target label can be indexed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7Yb76uofobY4"
      },
      "source": [
        "print(f\"The corresponding target is: {spike_targets[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "YTRqW-wtobY5"
      },
      "source": [
        "As a matter of interest, let's do that again but with 25% of the gain to promote sparsity. This time, we won't bother passing the targets into `spikegen.rate`, as we don't need it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ymxnM4CaobY5"
      },
      "source": [
        "spike_data = spikegen.rate(data_it, num_outputs=num_outputs, num_steps=num_steps, gain=0.25)\n",
        "\n",
        "spike_data_sample2 = spike_data[:, 0, 0]\n",
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample2, fig, ax)\n",
        "HTML(anim.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dicJdyG2obY5"
      },
      "source": [
        "# Uncomment for optional save\n",
        "# anim.save(\"spike_mnist_test2.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgPZBNIaobY5"
      },
      "source": [
        "Now let's average the spikes out over time and reconstruct the input images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e4ikMCQLobY6"
      },
      "source": [
        "plt.figure(facecolor=\"w\")\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(spike_data_sample.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.title('Gain = 1')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(spike_data_sample2.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.title('Gain = 0.25')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6bbbI1o2obY7"
      },
      "source": [
        "The case where `gain=0.25` is much lighter than where `gain=1`, as spiking probability has been reduced by a factor of x4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WpfpKe3zobY8"
      },
      "source": [
        "#### 2.2.2 Raster Plots\n",
        "Alternatively, we can generate a raster plot of an input sample. This requires reshaping our sample into a 2-D tensor, where the number of steps is the first entry. We then pass this sample into the function `spikeplot.raster`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KCpsLPySobY8"
      },
      "source": [
        "# Reshape\n",
        "spike_data_sample2 = spike_data_sample2.reshape((num_steps, -1))\n",
        "\n",
        "# raster plot\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data_sample2, ax, s=1.5, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WvhIdrAZobY9"
      },
      "source": [
        "We can also index into one single neuron. Below, we are indexing into the 210th neuron.\n",
        "Depending on your input data, you may need to index into a few different neurons between 0 & 784 before finding one that spikes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "R3kY3uoOobY9"
      },
      "source": [
        "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "splt.raster(spike_data_sample.reshape(num_steps, -1)[:,210].unsqueeze(1), ax, s=100, c=\"black\", marker=\"|\")\n",
        "\n",
        "plt.title(\"Input Neuron\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1lxp91nlobY-"
      },
      "source": [
        "The idea of rate coding is actually quite controversial. Multiple spikes are needed to achieve any sort of task, and each spike consumes power. It is unlikely to be the only mechanism within the brain, which is both resource-constrained and highly efficient.\r\n",
        "\r\n",
        "We know that the reaction time of a human is around 250ms. If the averaging firing rate of a neuron in the human brain is on the order of 10Hz, then we can only process about 2 spikes within our reaction timescale.\r\n",
        "\r\n",
        "On the other hand, biological neurons are somewhat stochastic. In fact,  neurons fail to fire around 70% of the time that our idealized models would have us believe. Spike rate coding offsets the power disadvantage by showing huge noise robustness: it's fine if some of the spikes fail to generte, because there will be plenty more where they came from.\r\n",
        "\r\n",
        "Rate coding is almost certainly working in conjunction with other encoding schemes in the brain. We'll consider these other encoding mechanisms in the following sections. \r\n",
        "\r\n",
        "This covers the `spikegen.rate` function. Further information on [can be found in the documentation here](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html).\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "enzqRvuNobY-"
      },
      "source": [
        "### 2.2 Latency Coding of MNIST\n",
        "Temporal codes capture information about the precise firing time of neurons; a single spike carries much more meaning than in rate codes which rely on firing frequency.\n",
        "\n",
        "While this opens up more susceptibility to noise, it can also decrease the power consumed by the hardware running SNN algorithms by orders of magnitude. \n",
        "\n",
        "`spikegen.latency` is a function that allows each input to fire at most **once** during the full time sweep.\n",
        "Features closer to `1` will fire earlier and features closer to `0` will fire later. I.e., in our MNIST case, bright pixels will fire earlier and dark pixels will fire later. \n",
        "\n",
        "By default, spike timing is calculated by setting the input feature as a current injection $I_{in}$ into an RC circuit. This current moves charge onto the capacitor, which increases $V(t)$. We assume that there is a trigger voltage, $V_{thr}$, which once reached, generates a spike. The question then becomes: *for a given input current (and equivalently, input feature), how long does it take for a spike to be generated?*\n",
        "\n",
        "Starting with Kirchhoff's current law, $I_{in} = I_R + I_C$, the rest of the derivation leads us to a logarithmic relationship between time and the input. \n",
        "\n",
        "If you've forgotten basic circuit theory and/or the following means nothing to you, then don't worry! All that matters is: **big** input means **fast** spike; **small** input means **late** spike.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_4_latencyrc.png?raw=true' width=\"600\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m835u23QobY-"
      },
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01, clip=False,\n",
        "                              normalize=False, linear=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AKDPjTvKobY_"
      },
      "source": [
        "* `tau`: by default, the input features are treated as a constant current injected into an RC circuit. `tau` is the RC time constant of the circuit. A higher `tau` will induce slower firing.\n",
        "* `threshold`: the membrane potential the RC circuit must charge to before it can fire. All features below the threshold are saturated.\n",
        "* `clip`: if `True`, spikes below the `threshold` are removed.\n",
        "* `normalize`: if `True`, the full range of firing is extended or squashed to fit `num_steps`.\n",
        "* `linear`: if True, the logarithmic firing latency of the RC circuit is replaced with a linear firing latency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VGH7b49SobY_"
      },
      "source": [
        "### 2.2.1 Raster plot\n",
        "We'll start with a raster this time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kypMtfF7obY_"
      },
      "source": [
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()\n",
        "\n",
        "fig.savefig('destination_path.png', format='png', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Hm1--DHYobZA"
      },
      "source": [
        "To make sense of your raster plot, you'll notice that high intensity features fire first, whereas low intensity features fire last:\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_5_latencyraster.png?raw=true' width=\"600\">\n",
        "</center>\n",
        "\n",
        "The logarithmic code coupled with the lack of diverse input values (i.e., the lack of midtone/grayscale features) causes significant clustering in two areas of the plot.\n",
        "The bright pixels induce firing at the start of the run, and the dark pixels at the end.\n",
        "We can increase `tau` to slow this down, or we can linearize the data by setting `linear=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZX8azDNWobZA"
      },
      "source": [
        "spike_data, spike_targets = spikegen.latency(data_it, targets_it, num_steps=100, tau=5, threshold=0.01, clip=False,\n",
        "                                              normalize=False, linear=True, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(*torch.where(spike_data[:, 0].view(100, -1).cpu()), s=25, c=\"black\")\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pZuk6g3NobZB"
      },
      "source": [
        "The spread of firing times is much more evenly distributed now. But notice all firing occurs within the first ~5 time steps, whereas the simulation range is 100 time steps.\n",
        "This indicates that we have a lot of redundant time steps doing nothing. This can be solved by either increasing `tau` to slow down the time constant, or setting `normalize=True` to span the full range of `num_steps`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RLgntdwSobZB"
      },
      "source": [
        "spike_data, spike_targets = spikegen.latency(data_it, targets_it, num_steps=100, tau=5, threshold=0.01, clip=False,\n",
        "                                              normalize=True, linear=True, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(*torch.where(spike_data[:, 0].view(100, -1).cpu()), s=25, c=\"black\")\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1EFIqaylobZC"
      },
      "source": [
        "One major advantage of spike-driven data is their sparsity, and their event-driven behavior.\n",
        "In the scenario shown above, a majority of the spikes occur at the final time step, where the input features fall below the threshold.\n",
        "We can remove these redundant features by setting `clip=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uowgb4FPobZC"
      },
      "source": [
        "spike_data, spike_targets = spikegen.latency(data_it, targets_it, num_steps=100, tau=5, threshold=0.01, clip=True,\n",
        "                                              normalize=True, linear=True, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(*torch.where(spike_data[:, 0].view(100, -1).cpu()), s=25, c=\"black\")\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "W7gN02QOobZC"
      },
      "source": [
        "That looks much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XG9erdfxobZD"
      },
      "source": [
        "### 2.2.2 Animation\n",
        "We will run the exact same code block as before to create an animation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BjLC1Pl_obZD"
      },
      "source": [
        "spike_data_sample = spike_data[:, 0, 0]\n",
        "print(spike_data_sample.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uwVwMVpzobZD"
      },
      "source": [
        "spike_data_sample = spike_data_sample.cpu()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "camera = Camera(fig)\n",
        "plt.axis('off')\n",
        "\n",
        "# iterate over time and take a snapshot with celluloid\n",
        "for time in range(num_steps):\n",
        "    im = ax.imshow(spike_data_sample[time, :, :], cmap='plasma')\n",
        "    camera.snap()\n",
        "\n",
        "# interval=100 specifies 100ms delay between frames\n",
        "anim = camera.animate(interval=100)\n",
        "HTML(anim.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VgNLaB90obZD"
      },
      "source": [
        "# Save output: .gif, .mp4 etc.\n",
        "anim.save(\"mnist_latency.gif\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FONW5DIkobZE"
      },
      "source": [
        "This animation is obviously much tougher to make out in video form, but a keen eye will be able to catch a glimpse of the initial frame where most of the spikes occur.\n",
        "We can index into the corresponding target value to check what value it is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wrqfPu43obZE"
      },
      "source": [
        "print(spike_targets[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mxrGoLIjobZE"
      },
      "source": [
        "## 3. Spike Generation\n",
        "Now say we just want a randomly generated spike train from scratch.\n",
        "`spikegen.rate` has a nested function, `rate_conv` which takes care of the feature $\\rightarrow$ spike conversion process.\n",
        "All we have to do is initialize a randomly generated `torchTensor` to pass in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-Q_7uj0vobZE"
      },
      "source": [
        "# Create a random spike train\n",
        "spike_prob = torch.rand((num_steps, 28, 28), device=device, dtype=dtype) * 0.5\n",
        "spike_rand = spikegen.rate_conv(spike_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KOy-NZ5YobZF"
      },
      "source": [
        "3.1 Animation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yCIwKN0WobZF"
      },
      "source": [
        "spike_data = spike_data.cpu()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "camera = Camera(fig)\n",
        "plt.axis('off')\n",
        "\n",
        "# iterate over time and take a snapshot with celluloid\n",
        "for time in range(num_steps):\n",
        "    im = ax.imshow(spike_rand[time, :, :], cmap='plasma')\n",
        "    camera.snap()\n",
        "\n",
        "# interval=40 specifies 40ms delay between frames\n",
        "anim = camera.animate(interval=40)\n",
        "HTML(anim.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kx-VKWxFobZF"
      },
      "source": [
        "# Save output: .gif, .mp4 etc.\n",
        "anim.save(\"random_spikes.gif\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "C_IH912xobZF"
      },
      "source": [
        "3.2 Raster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F6QgcKCrobZF"
      },
      "source": [
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(*torch.where(spike_rand[:, 0].view(100, -1).cpu()), s=25, c=\"black\")\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "N-SsITWKobZF"
      },
      "source": [
        "That's it for spike conversion and generation. \n",
        "This approach generalizes beyond images, to single-dimensional and multi-dimensional tensors.\n",
        "Next up, we'll try to do some learning using both static MNIST and our own generated spiking MNIST."
      ]
    }
  ]
}