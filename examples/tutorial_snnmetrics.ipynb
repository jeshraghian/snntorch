{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bFuCzJCcUOC"
      },
      "source": [
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"300\">](https://github.com/jeshraghian/snntorch/)\n",
        "\n",
        "# snnMetrics Tutorial\n",
        "### Tutorial written by Sahil Konjarla\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/quickstart.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/ruhai-lin/SNN-Exoplanet-Hunter) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/ruhai-lin/SNN-Exoplanet-Hunter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzEOEBzWp2wa"
      },
      "source": [
        "For a comprehensive overview on how SNNs work, and what is going on under the hood, [then you might be interested in the snnTorch tutorial series available here.](https://snntorch.readthedocs.io/en/latest/tutorials/index.html)\n",
        "The snnTorch tutorial series is based on the following paper. If you find these resources or code useful in your work, please consider citing the following source:\n",
        "\n",
        "\n",
        "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". Proceedings of the IEEE, 111(9) September 2023.](https://ieeexplore.ieee.org/abstract/document/10242251) </cite>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Introduction\n",
        "\n",
        "In this tutorial, you will learn how to combine snnTorch and snnMetrics to:\n",
        "* calculate the number of synaptic operations in a single patch\n",
        "* calculate the number of synaptic operations in a epoch\n",
        "\n",
        "During this tutorial we will be using the original static MNIST dataset and train a multi-layer fully-connected spiking neural network and a multi-layer convolutional spiking neural network. Calculating the batch and epoch synaptic statistics for each network.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pSkJoFTb4E68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. snnMetrics\n",
        "Before we get into the bulk of this tutorial, it is beneficial to understand what exactly is snnMetrics and what are the benefits of using snnMetrics in your spikng neural network code."
      ],
      "metadata": {
        "id": "ezjjGD0YDtnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 What is snnMetrics\n",
        "snnMetrics is an open-source python library, made by Gregor Lenz, that can be used to provide metrics that are specific for spiking neural networks. The API is similar to [torchmetrics](https://lightning.ai/docs/torchmetrics/stable) and the package is currently in beta phase.\n"
      ],
      "metadata": {
        "id": "6n02glnmKmho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The current usage of snnMetrics allows users to track the number of spikes or synapic operations that occur in a single batch of training or during a single epoch. This tracking can allow us to understand the:\n",
        "* Allows you to understand how the data you are passing through is affecting your network\n",
        "* It can be used to do energy efficiency analysis, especially if you are using neuromorphic hardware.\n",
        "* Can be used to understand network perfomance and optimization\n",
        "* can provide insight into fault detection and help you diagnose any issues in your network\n",
        "* Due to SNNs being adpet in processing temportal information, we can analyze spike patters and get insight into how the network handles time-dependent data\n",
        "* It can also be used to track the number of firing neurons in your ANN layers"
      ],
      "metadata": {
        "id": "pjg6eD2iU7SN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more information on snnMetrics please check out the documentation page [here](https://snnmetrics.readthedocs.io/en/latest/index.html) or the [github page](https://github.com/open-neuromorphic/snnmetrics). Now let us get into how we can use snnMetrics."
      ],
      "metadata": {
        "id": "yXIBTrfhU9Ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. snnMetrics Startup"
      ],
      "metadata": {
        "id": "oHfMhXckVSQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to initialize a new Git repository in our current directory, if you are using Google Colab if will just make a new directory in the runtime. Then instiall the Python Build Reasonablness package which helps simplify Python package movement. Furthermore, we need to install the snntorch python library and finally install snnmetrics."
      ],
      "metadata": {
        "id": "ZQ2ZKAqgWCRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git init --quiet\n",
        "!pip install pbr --quiet\n",
        "!pip install snntorch --quiet\n",
        "!pip install snnmetrics --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQSuLrwWVlip",
        "outputId": "b9dd1bbf-d0ac-4b9a-85ca-68e9eb2ef069"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then import the following libraries below."
      ],
      "metadata": {
        "id": "XEA_qldDadQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pbr # to manage the packages\n",
        "\n",
        "# snntorch\n",
        "import snntorch as snn\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import spikegen\n",
        "\n",
        "# snnmetrics\n",
        "import snnmetrics as sm\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "0qjVr7jYajSg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Setting up the Static MNIST Dataset"
      ],
      "metadata": {
        "id": "FI10tOHhdBUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader arguements\n",
        "batch_size = 128\n",
        "data_path='/data/mnist'\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "RIM8coa1dU7z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws_8Wbt5dcrO",
        "outputId": "7ad74214-edcc-4fb3-ed13-190aa2ce62c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 115134368.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 10527130.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 31976416.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 17131770.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the above code blocks throws an error, e.g. the MNIST servers are down, then uncomment the following code instead."
      ],
      "metadata": {
        "id": "D970LT9cdmrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# temporary dataloader if MNIST service is unavailable\n",
        "# !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "# !tar -zxvf MNIST.tar.gz\n",
        "\n",
        "# mnist_train = datasets.MNIST(root = './', train=True, download=True, transform=transform)\n",
        "# mnist_test = datasets.MNIST(root = './', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "5pxzZb-ndmNH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "E9Ixo8LMdyFn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Setting up Metric Computation"
      ],
      "metadata": {
        "id": "iPt_K5ufWBtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of snnMetrics\n",
        "# Calculating the number of synops per ANN and SNN layer\n",
        "def metric_computation(ops_layer, spks):\n",
        "    batch_stats_layer = ops_layer(spks)\n",
        "    synops_per_neuron = batch_stats_layer['synops_per_neuron']\n",
        "    synops = batch_stats_layer['synops']\n",
        "    ops_layer.reset()\n",
        "    return synops"
      ],
      "metadata": {
        "id": "KaXX6nWEWNXL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the number of synaptic operations per batch\n",
        "def synops_printer(fc1_synops,\n",
        "        lif1_synops, fc2_synops,lif2_synops):\n",
        "    total_synops_per_batch = fc1_synops + fc2_synops + lif1_synops + lif2_synops\n",
        "    print(f\"Synops for Linear Layer: {fc1_synops}\")\n",
        "    print(f\"Synops for SNN Layer: {lif1_synops}\")\n",
        "    print(f\"Synops for Linear layer: {fc2_synops}\")\n",
        "    print(f\"Synops for SNN Layer: {lif2_synops}\")\n",
        "    print(f\"Total Synops: {total_synops_per_batch}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "FqC9UKZEW_QB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are defining a function that can calculate the metrics per batch. The inputs of our function are `ops_layer` and `spks`. `ops_layer` refers to the snnMetric layer that we add to our network, I will go into this more in the next section. `spks` refers to the spike tensor that is returned from adding a spiking layer to the network.\n",
        "\n",
        "The actual computation is done by using:\n",
        "* `batch_stats_layer` refers to the metrics layer where we pass in the spiking tensor `spks`\n",
        "* `synops_per_neuron` attains the number of spikes per nueron\n",
        "* `synops` gets the total number of synaptic operations that occured in that layer per each batch\n",
        "\n",
        "At the end of our function we are reseting the `ops_layer` so that we have a clean layer."
      ],
      "metadata": {
        "id": "dP3EDqV9WT77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Define a Fully-Connected SNN Network"
      ],
      "metadata": {
        "id": "wixRfltPUzQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Network Architecture\n",
        "num_inputs = 28*28\n",
        "num_hidden = 1000\n",
        "num_outputs = 10\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 25\n",
        "beta = 0.95"
      ],
      "metadata": {
        "id": "mtXwvfGuVxd5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code follows a similar syntax as the official [snnTorch tutorials](https://snntorch.readthedocs.io/en/latest/tutorials/index.html), but we are adding snnMetrics layers along with some other code."
      ],
      "metadata": {
        "id": "xx85QB3Kc_FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.linear_layer1 = sm.SynOps(fanout=num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.snn_layer1 = sm.SynOps(fanout=num_hidden)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.linear_layer2 = sm.SynOps(fanout=num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.snn_layer2 = sm.SynOps(fanout=num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        # Define a threshold\n",
        "        threshold_value = 0.0001\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            # First Layer\n",
        "            cur1 = self.fc1(x.flatten(1))\n",
        "            thresholded_output = torch.where(cur1 > threshold_value, torch.tensor(1.0), torch.tensor(0.0))\n",
        "            fc1_synops = metric_computation(self.linear_layer1, thresholded_output)\n",
        "\n",
        "            # Second Layer\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            lif1_synops = metric_computation(self.snn_layer1, spk1)\n",
        "\n",
        "            # Third Layer\n",
        "            cur2 = self.fc2(spk1)\n",
        "            thresholded_output2 = torch.where(cur2 > threshold_value, torch.tensor(1.0), torch.tensor(0.0))\n",
        "            fc2_synops = metric_computation(self.linear_layer2, thresholded_output2)\n",
        "\n",
        "            # Fourth Layer\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            lif2_synops = metric_computation(self.snn_layer2, spk2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return fc1_synops, fc2_synops, lif1_synops, lif2_synops, torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "G_QsQNESV3JG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The definition of the network is very simlar to the tutorials, but we are adding snnMetrics layer inbetween every ANN and snntorch layer. They are defined as:\n",
        "* `linear_layer1`\n",
        "* `snn_layer1`\n",
        "* `linear_layer2`\n",
        "* `snn_layer2`\n",
        "\n",
        "Here as you can see I defined each layer to be a snnMetrics layer `sm.SynOps()`. `sm.SynOps` takes in as an argument `fanout` which refers to the number of connections to the next layer. In this case we are refering it to be the our `num_hidden` and `num_outputs`.\n"
      ],
      "metadata": {
        "id": "G44K3_kdeYGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the `forward()` function I have defined a variable `threshold_value`. `threshold_value` was defined so that we could turn the tensor output from the linear transformation into spiking tensor. Using the Pytorch function `torch.where()`, which allowed for snnMetrics to be able to calculate the number of synaptic operations in a linear layer.\n",
        "\n",
        "* `threshold_output` takes the output from the linear layer and converts it into a tensor of 0s and 1s.\n",
        "* `fc` passes the snnMetrics layer defined and the spikes tensor into the `metric_computation` function that we have defined earlier\n",
        "* `lif` pass the snnMetrics layer defind and the spikes tensor into the `metric_computation` function that we have defined earlier\n",
        "\n",
        "Finally, the network returns all the synaptic operations for each layer so that our print function and give us those values for each test and train loop."
      ],
      "metadata": {
        "id": "cJMtML-2huIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Training Fully-Connected SNN Network"
      ],
      "metadata": {
        "id": "Ax47QhYokQS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Define the Loss function and the Optimizer"
      ],
      "metadata": {
        "id": "oCK1-64ek1yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999)) # Adam op[timizer with a learning rate of 5e^-4\n",
        "loss = nn.CrossEntropyLoss() # Cross Entropy Loss function"
      ],
      "metadata": {
        "id": "6LL8KZjakdUB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Training and Testing model"
      ],
      "metadata": {
        "id": "0mT95m9H4HnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to be training for one epoch and print out the synaptic operations for each."
      ],
      "metadata": {
        "id": "452Gp0G75sLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "    iter_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data, targets in train_batch:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        fc1_synops, fc2_synops, lif1_synops, lif2_synops, spk2_rec, mem2_rec = net(data.view(batch_size, -1))\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "        for step in range(num_steps):\n",
        "            loss_val += loss(mem2_rec[step], targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Print Synops per batch\n",
        "        print(f\"Train Synops {counter}:\")\n",
        "        synops_printer(fc1_synops, lif1_synops, fc2_synops, lif2_synops)\n",
        "\n",
        "        # Test set\n",
        "        with torch.no_grad():\n",
        "            net.eval()\n",
        "            test_data, test_targets = next(iter(test_loader))\n",
        "            test_data = test_data.to(device)\n",
        "            test_targets = test_targets.to(device)\n",
        "\n",
        "            # Test set forward pass\n",
        "            test_fc1_synops, test_fc2_synops, test_lif1_synops, test_lif2_synops, test_spk2_rec, test_mem = net(test_data.view(batch_size, -1))\n",
        "\n",
        "            # Test set loss\n",
        "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
        "            for step in range(num_steps):\n",
        "                test_loss += loss(test_mem[step], test_targets)\n",
        "            test_loss_hist.append(test_loss.item())\n",
        "\n",
        "            # Print train/test loss/accuracy\n",
        "            print(f\"Test Synops: {counter}\")\n",
        "            synops_printer(test_fc1_synops, test_lif1_synops, test_fc2_synops, test_lif2_synops)\n",
        "\n",
        "            # Exit rule\n",
        "            counter += 1\n",
        "            if counter == 20:\n",
        "                break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hoT7uoO4HRY",
        "outputId": "dfbadaea-0cec-4935-cd41-a0064ed94475"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Synops 0:\n",
            "Synops for Linear Layer: 498335.9375\n",
            "Synops for SNN Layer: 52304.6875\n",
            "Synops for Linear layer: 54.453125\n",
            "Synops for SNN Layer: 1.953125\n",
            "Total Synops: 550697.0\n",
            "\n",
            "\n",
            "Test Synops: 0\n",
            "Synops for Linear Layer: 496140.625\n",
            "Synops for SNN Layer: 54328.125\n",
            "Synops for Linear layer: 56.640625\n",
            "Synops for SNN Layer: 1.953125\n",
            "Total Synops: 550527.3125\n",
            "\n",
            "\n",
            "Train Synops 1:\n",
            "Synops for Linear Layer: 493812.5\n",
            "Synops for SNN Layer: 53031.25\n",
            "Synops for Linear layer: 54.453125\n",
            "Synops for SNN Layer: 1.5625\n",
            "Total Synops: 546899.75\n",
            "\n",
            "\n",
            "Test Synops: 1\n",
            "Synops for Linear Layer: 495656.25\n",
            "Synops for SNN Layer: 56054.6875\n",
            "Synops for Linear layer: 55.703125\n",
            "Synops for SNN Layer: 5.234375\n",
            "Total Synops: 551771.875\n",
            "\n",
            "\n",
            "Train Synops 2:\n",
            "Synops for Linear Layer: 497320.3125\n",
            "Synops for SNN Layer: 53968.75\n",
            "Synops for Linear layer: 55.625\n",
            "Synops for SNN Layer: 2.96875\n",
            "Total Synops: 551347.625\n",
            "\n",
            "\n",
            "Test Synops: 2\n",
            "Synops for Linear Layer: 501437.5\n",
            "Synops for SNN Layer: 57281.25\n",
            "Synops for Linear layer: 54.21875\n",
            "Synops for SNN Layer: 3.828125\n",
            "Total Synops: 558776.8125\n",
            "\n",
            "\n",
            "Train Synops 3:\n",
            "Synops for Linear Layer: 499773.4375\n",
            "Synops for SNN Layer: 56242.1875\n",
            "Synops for Linear layer: 54.453125\n",
            "Synops for SNN Layer: 3.4375\n",
            "Total Synops: 556073.5\n",
            "\n",
            "\n",
            "Test Synops: 3\n",
            "Synops for Linear Layer: 513148.4375\n",
            "Synops for SNN Layer: 64539.0625\n",
            "Synops for Linear layer: 52.03125\n",
            "Synops for SNN Layer: 5.078125\n",
            "Total Synops: 577744.5625\n",
            "\n",
            "\n",
            "Train Synops 4:\n",
            "Synops for Linear Layer: 512085.9375\n",
            "Synops for SNN Layer: 63078.125\n",
            "Synops for Linear layer: 51.640625\n",
            "Synops for SNN Layer: 5.9375\n",
            "Total Synops: 575221.625\n",
            "\n",
            "\n",
            "Test Synops: 4\n",
            "Synops for Linear Layer: 525140.625\n",
            "Synops for SNN Layer: 66695.3125\n",
            "Synops for Linear layer: 50.078125\n",
            "Synops for SNN Layer: 6.40625\n",
            "Total Synops: 591892.375\n",
            "\n",
            "\n",
            "Train Synops 5:\n",
            "Synops for Linear Layer: 524742.1875\n",
            "Synops for SNN Layer: 64093.75\n",
            "Synops for Linear layer: 52.109375\n",
            "Synops for SNN Layer: 6.5625\n",
            "Total Synops: 588894.625\n",
            "\n",
            "\n",
            "Test Synops: 5\n",
            "Synops for Linear Layer: 541226.5625\n",
            "Synops for SNN Layer: 69359.375\n",
            "Synops for Linear layer: 49.375\n",
            "Synops for SNN Layer: 6.875\n",
            "Total Synops: 610642.1875\n",
            "\n",
            "\n",
            "Train Synops 6:\n",
            "Synops for Linear Layer: 540375.0\n",
            "Synops for SNN Layer: 67898.4375\n",
            "Synops for Linear layer: 48.125\n",
            "Synops for SNN Layer: 6.5625\n",
            "Total Synops: 608328.125\n",
            "\n",
            "\n",
            "Test Synops: 6\n",
            "Synops for Linear Layer: 556843.75\n",
            "Synops for SNN Layer: 76210.9375\n",
            "Synops for Linear layer: 48.515625\n",
            "Synops for SNN Layer: 9.0625\n",
            "Total Synops: 633112.25\n",
            "\n",
            "\n",
            "Train Synops 7:\n",
            "Synops for Linear Layer: 560625.0\n",
            "Synops for SNN Layer: 77328.125\n",
            "Synops for Linear layer: 49.375\n",
            "Synops for SNN Layer: 7.890625\n",
            "Total Synops: 638010.375\n",
            "\n",
            "\n",
            "Test Synops: 7\n",
            "Synops for Linear Layer: 573898.4375\n",
            "Synops for SNN Layer: 80835.9375\n",
            "Synops for Linear layer: 47.734375\n",
            "Synops for SNN Layer: 9.84375\n",
            "Total Synops: 654792.0\n",
            "\n",
            "\n",
            "Train Synops 8:\n",
            "Synops for Linear Layer: 572726.5625\n",
            "Synops for SNN Layer: 83335.9375\n",
            "Synops for Linear layer: 46.25\n",
            "Synops for SNN Layer: 8.046875\n",
            "Total Synops: 656116.8125\n",
            "\n",
            "\n",
            "Test Synops: 8\n",
            "Synops for Linear Layer: 595906.25\n",
            "Synops for SNN Layer: 93093.75\n",
            "Synops for Linear layer: 44.609375\n",
            "Synops for SNN Layer: 10.3125\n",
            "Total Synops: 689054.9375\n",
            "\n",
            "\n",
            "Train Synops 9:\n",
            "Synops for Linear Layer: 586835.9375\n",
            "Synops for SNN Layer: 89625.0\n",
            "Synops for Linear layer: 47.1875\n",
            "Synops for SNN Layer: 10.625\n",
            "Total Synops: 676518.75\n",
            "\n",
            "\n",
            "Test Synops: 9\n",
            "Synops for Linear Layer: 611859.375\n",
            "Synops for SNN Layer: 101671.875\n",
            "Synops for Linear layer: 44.0625\n",
            "Synops for SNN Layer: 12.1875\n",
            "Total Synops: 713587.5\n",
            "\n",
            "\n",
            "Train Synops 10:\n",
            "Synops for Linear Layer: 606125.0\n",
            "Synops for SNN Layer: 96578.125\n",
            "Synops for Linear layer: 44.375\n",
            "Synops for SNN Layer: 12.890625\n",
            "Total Synops: 702760.375\n",
            "\n",
            "\n",
            "Test Synops: 10\n",
            "Synops for Linear Layer: 624773.4375\n",
            "Synops for SNN Layer: 107937.5\n",
            "Synops for Linear layer: 42.96875\n",
            "Synops for SNN Layer: 13.4375\n",
            "Total Synops: 732767.3125\n",
            "\n",
            "\n",
            "Train Synops 11:\n",
            "Synops for Linear Layer: 623203.125\n",
            "Synops for SNN Layer: 104640.625\n",
            "Synops for Linear layer: 43.4375\n",
            "Synops for SNN Layer: 12.265625\n",
            "Total Synops: 727899.4375\n",
            "\n",
            "\n",
            "Test Synops: 11\n",
            "Synops for Linear Layer: 639664.0625\n",
            "Synops for SNN Layer: 113500.0\n",
            "Synops for Linear layer: 42.578125\n",
            "Synops for SNN Layer: 14.140625\n",
            "Total Synops: 753220.75\n",
            "\n",
            "\n",
            "Train Synops 12:\n",
            "Synops for Linear Layer: 636812.5\n",
            "Synops for SNN Layer: 110906.25\n",
            "Synops for Linear layer: 43.59375\n",
            "Synops for SNN Layer: 13.203125\n",
            "Total Synops: 747775.5625\n",
            "\n",
            "\n",
            "Test Synops: 12\n",
            "Synops for Linear Layer: 657468.75\n",
            "Synops for SNN Layer: 126031.25\n",
            "Synops for Linear layer: 42.34375\n",
            "Synops for SNN Layer: 13.515625\n",
            "Total Synops: 783555.875\n",
            "\n",
            "\n",
            "Train Synops 13:\n",
            "Synops for Linear Layer: 654031.25\n",
            "Synops for SNN Layer: 119726.5625\n",
            "Synops for Linear layer: 42.5\n",
            "Synops for SNN Layer: 12.5\n",
            "Total Synops: 773812.8125\n",
            "\n",
            "\n",
            "Test Synops: 13\n",
            "Synops for Linear Layer: 665476.5625\n",
            "Synops for SNN Layer: 132367.1875\n",
            "Synops for Linear layer: 40.0\n",
            "Synops for SNN Layer: 14.296875\n",
            "Total Synops: 797898.0625\n",
            "\n",
            "\n",
            "Train Synops 14:\n",
            "Synops for Linear Layer: 666851.5625\n",
            "Synops for SNN Layer: 128906.25\n",
            "Synops for Linear layer: 41.09375\n",
            "Synops for SNN Layer: 13.359375\n",
            "Total Synops: 795812.25\n",
            "\n",
            "\n",
            "Test Synops: 14\n",
            "Synops for Linear Layer: 677679.6875\n",
            "Synops for SNN Layer: 140328.125\n",
            "Synops for Linear layer: 40.390625\n",
            "Synops for SNN Layer: 14.609375\n",
            "Total Synops: 818062.8125\n",
            "\n",
            "\n",
            "Train Synops 15:\n",
            "Synops for Linear Layer: 676273.4375\n",
            "Synops for SNN Layer: 131781.25\n",
            "Synops for Linear layer: 40.078125\n",
            "Synops for SNN Layer: 13.90625\n",
            "Total Synops: 808108.625\n",
            "\n",
            "\n",
            "Test Synops: 15\n",
            "Synops for Linear Layer: 687453.125\n",
            "Synops for SNN Layer: 150679.6875\n",
            "Synops for Linear layer: 39.53125\n",
            "Synops for SNN Layer: 16.796875\n",
            "Total Synops: 838189.125\n",
            "\n",
            "\n",
            "Train Synops 16:\n",
            "Synops for Linear Layer: 685710.9375\n",
            "Synops for SNN Layer: 146273.4375\n",
            "Synops for Linear layer: 39.375\n",
            "Synops for SNN Layer: 15.078125\n",
            "Total Synops: 832038.8125\n",
            "\n",
            "\n",
            "Test Synops: 16\n",
            "Synops for Linear Layer: 695445.3125\n",
            "Synops for SNN Layer: 149898.4375\n",
            "Synops for Linear layer: 37.34375\n",
            "Synops for SNN Layer: 15.15625\n",
            "Total Synops: 845396.25\n",
            "\n",
            "\n",
            "Train Synops 17:\n",
            "Synops for Linear Layer: 693234.375\n",
            "Synops for SNN Layer: 149718.75\n",
            "Synops for Linear layer: 39.0625\n",
            "Synops for SNN Layer: 16.71875\n",
            "Total Synops: 843008.875\n",
            "\n",
            "\n",
            "Test Synops: 17\n",
            "Synops for Linear Layer: 706343.75\n",
            "Synops for SNN Layer: 158773.4375\n",
            "Synops for Linear layer: 37.5\n",
            "Synops for SNN Layer: 17.421875\n",
            "Total Synops: 865172.125\n",
            "\n",
            "\n",
            "Train Synops 18:\n",
            "Synops for Linear Layer: 705398.4375\n",
            "Synops for SNN Layer: 159968.75\n",
            "Synops for Linear layer: 38.75\n",
            "Synops for SNN Layer: 16.953125\n",
            "Total Synops: 865422.875\n",
            "\n",
            "\n",
            "Test Synops: 18\n",
            "Synops for Linear Layer: 712460.9375\n",
            "Synops for SNN Layer: 164992.1875\n",
            "Synops for Linear layer: 36.875\n",
            "Synops for SNN Layer: 16.796875\n",
            "Total Synops: 877506.8125\n",
            "\n",
            "\n",
            "Train Synops 19:\n",
            "Synops for Linear Layer: 709507.8125\n",
            "Synops for SNN Layer: 158562.5\n",
            "Synops for Linear layer: 38.28125\n",
            "Synops for SNN Layer: 17.734375\n",
            "Total Synops: 868126.375\n",
            "\n",
            "\n",
            "Test Synops: 19\n",
            "Synops for Linear Layer: 719335.9375\n",
            "Synops for SNN Layer: 176578.125\n",
            "Synops for Linear layer: 37.734375\n",
            "Synops for SNN Layer: 17.265625\n",
            "Total Synops: 895969.0625\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Training a Convolutional Network"
      ],
      "metadata": {
        "id": "I5FBWq706K5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Define New Synops Print Function"
      ],
      "metadata": {
        "id": "HlfXtr36Yg-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the number of synaptic operations per layer and batch\n",
        "def synops_printer(conv1_synops, lif1_synops,\n",
        "                   conv2_synops,lif2_synops, fc_synops, lif3_synops):\n",
        "    total_synops_per_batch = conv1_synops + conv2_synops + lif1_synops + lif2_synops + fc_layer + lif3_synops\n",
        "    print(f\"Synops for Conv Layer: {conv1_synops}\")\n",
        "    print(f\"Synops for SNN Layer: {lif1_synops}\")\n",
        "    print(f\"Synops for Conv layer: {conv2_synops}\")\n",
        "    print(f\"Synops for SNN Layer: {lif2_synops}\")\n",
        "    print(f\"Synops for Linear Layer: {fc_synops}\")\n",
        "    print(f\"Synops for SNN Layer: {lif3_synops}\")\n",
        "    print(f\"Total Synops: {total_synops_per_batch}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "Y6FnL-aKYnzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.2 Define a Convolutional Network"
      ],
      "metadata": {
        "id": "tyO73yLi6cst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code follows a similar syntax to our fully-connected layer model and training, but instead we are going to be changing some aspects to fit the concolutional model."
      ],
      "metadata": {
        "id": "WG_cSwrpdOki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.conv1 = nn.Conv2d(1, 24, 5, padding=\"same\")\n",
        "        self.conv1_layer = sm.SynOps(fanout=24)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.lif1_layer = sm.SynOps(fanout=24)\n",
        "        self.mp1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(24, 28, 5, padding=\"same\")\n",
        "        self.conv2_layer = sm.SynOps(fanout=7)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.lif2_layer = sm.SynOps(fanout=7)\n",
        "        self.mp2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.fc = nn.Linear(28 * 7 * 7, 10)\n",
        "        self.linear_layer = sm.SynOps(fanout=10)\n",
        "        self.lif3 = snn.Leaky(beta=beta)\n",
        "        self.lif3_layer = sm.SynOps(fanout=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk3_rec = []\n",
        "\n",
        "        # Define a threshold\n",
        "        threshold_value = 0.0001\n",
        "\n",
        "        # time-loop\n",
        "        for step in range(num_steps):\n",
        "            # First Layer\n",
        "            cur1 = self.conv1(x)\n",
        "            thresholded_output = torch.where(cur1 > threshold_value, torch.tensor(1.0), torch.tensor(0.0))\n",
        "            conv1_synops = metric_computation(self.conv1_layer, thresholded_output)\n",
        "            spk1, mem1 = self.lif1(self.mp1(cur1), mem1)\n",
        "            lif1_synops = metric_computation(self.lif1_layer, spk1)\n",
        "\n",
        "            # Second Layer\n",
        "            cur2 = self.conv2(spk1)\n",
        "            thresholded_output2 = torch.where(cur2 > threshold_value, torch.tensor(1.0), torch.tensor(0.0))\n",
        "            conv2_synops = metric_computation(self.conv2_layer, thresholded_output2)\n",
        "            spk2, mem2 = self.lif2(self.mp2(cur2), mem2)\n",
        "            lif2_synops = metric_computation(self.lif2_layer, spk2)\n",
        "\n",
        "            # Third Layer\n",
        "            cur3 = self.fc(spk2.flatten(1))\n",
        "            thresholded_output3 = torch.where(cur3 > threshold_value, torch.tensor(1.0), torch.tensor(0.0))\n",
        "            fc_synops = metric_computation(self.linear_layer, thresholded_output3)\n",
        "            spk3, mem3 = self.lif3(cur3, mem3)\n",
        "            lif3_synops = metric_computation(self.lif3_layer, spk3)\n",
        "\n",
        "            spk3_rec.append(spk3)\n",
        "\n",
        "        return conv1_synops, lif1_synops, conv2_synops, lif2_synops, fc_synops, lif3_synops, torch.stack(spk3_rec, dim=0)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "convnet = ConvNet().to(device)"
      ],
      "metadata": {
        "id": "1Vwsy9pL6hmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The definition of the convolutional network is very similar to fully-connected network we defined above, but we are adding convolutional layers instead of fully-connected layers and we are max pooling at the end. We defined synops layers:\n",
        "* `conv1_layer`\n",
        "* `lif1_layer`\n",
        "* `conv2_layer`\n",
        "* `lif2_layer`\n",
        "* `linear_layer`\n",
        "* `lif3_layer`\n",
        "\n",
        "The snnMetrics syntax is all the same, but we are going to be chaning the fanout, similar to what we did for the fully-connected layers. Setting the fanouts to be respectivly, 24,7,10. The connections get smaller and smaller due to the fact that we are using maxpooling.\n"
      ],
      "metadata": {
        "id": "zG892KQ4dDAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 Define the Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "_fvA-JO7beGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(convnet.parameters(), lr=5e-4, betas=(0.9, 0.999)) # Adam op[timizer with a learning rate of 5e^-4\n",
        "loss = nn.CrossEntropyLoss() # Cross Entropy Loss function"
      ],
      "metadata": {
        "id": "6ZUXc8DNbm76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4 Training Convolutional Network\n"
      ],
      "metadata": {
        "id": "JdwOJzKbaXyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data, targets in train_batch:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        spk3_rec = []\n",
        "        convnet.train()\n",
        "        conv1_synops, lif1_synops, conv2_synops, lif2_synops, fc_layer, lif3_synops, spk3_rec = convnet(data)\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "        loss_val = loss(spk3_rec.sum(0), targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Print train/test loss/accuracy\n",
        "        print(\"Train Synops\")\n",
        "        synops_printer(conv1_synops, lif1_synops, conv2_synops, lif2_synops, fc_layer, lif3_synops)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            convnet.eval()\n",
        "            test_data, test_targets = next(iter(test_loader))\n",
        "            test_data = test_data.to(device)\n",
        "            test_targets = test_targets.to(device)\n",
        "\n",
        "            # Test set forward pass\n",
        "            test_conv1_synops, test_lif1_synops, test_conv2_synops, test_lif2_synops, test_fc_synops, test_lif3_synops, test_spk3_rec  = convnet(test_data.view(batch_size, 1, 28, 28))\n",
        "\n",
        "            # Test set loss\n",
        "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
        "            for step in range(num_steps):\n",
        "                test_loss += loss(test_spk3_rec[step], test_targets)\n",
        "            test_loss_hist.append(test_loss.item())\n",
        "\n",
        "            # Print train/test loss/accuracy\n",
        "            print(f\"Test Synops:\")\n",
        "            synops_printer(conv1_synops, lif1_synops, conv2_synops, lif2_synops, fc_layer, lif3_synops)\n",
        "\n",
        "            # Exit rule\n",
        "            counter += 1\n",
        "            if counter == 120:\n",
        "                break"
      ],
      "metadata": {
        "id": "xvA2kqFWaXYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "0eWkV-eubT1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now after completing this tutorial you should know how to constuct and train fully-connected and convolutional networks on a static dataset. The snnMetrics library is still in its early stages, but it has so many applications and uses that will greatly benefit the neuromorphic computing community. Armed with this knowledge, you should now be able to perform different benchmarking and testing on your spiking neural networks."
      ],
      "metadata": {
        "id": "uVXVtCmzoPti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UhhttDn5p1nE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Resources\n",
        "\n",
        "* [Check out the snnMetric Github project here](https://github.com/open-neuromorphic/snnmetrics)\n",
        "* [Check out the snnTorch Github projet here](https://github.com/jeshraghian/snntorch)"
      ],
      "metadata": {
        "id": "aPKsp8ECpBka"
      }
    }
  ]
}